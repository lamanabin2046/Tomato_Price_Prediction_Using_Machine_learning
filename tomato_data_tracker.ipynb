{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "565637c8-68e5-45a4-b742-848ab5570cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 01/01/2022\n",
      "Saved data to arrival_01_01_2022.csv\n",
      "Processing 01/02/2022\n",
      "Saved data to arrival_01_02_2022.csv\n",
      "Processing 01/03/2022\n",
      "Saved data to arrival_01_03_2022.csv\n",
      "Processing 01/04/2022\n",
      "Saved data to arrival_01_04_2022.csv\n",
      "Processing 01/05/2022\n",
      "Saved data to arrival_01_05_2022.csv\n",
      "Processing 01/06/2022\n",
      "Saved data to arrival_01_06_2022.csv\n",
      "Processing 01/07/2022\n",
      "Saved data to arrival_01_07_2022.csv\n",
      "Processing 01/08/2022\n",
      "Saved data to arrival_01_08_2022.csv\n",
      "Processing 01/09/2022\n",
      "Saved data to arrival_01_09_2022.csv\n",
      "Processing 01/10/2022\n",
      "Saved data to arrival_01_10_2022.csv\n",
      "Processing 01/11/2022\n",
      "Saved data to arrival_01_11_2022.csv\n",
      "Processing 01/12/2022\n",
      "Saved data to arrival_01_12_2022.csv\n",
      "Processing 01/13/2022\n",
      "Saved data to arrival_01_13_2022.csv\n",
      "Processing 01/14/2022\n",
      "Saved data to arrival_01_14_2022.csv\n",
      "Processing 01/15/2022\n",
      "Saved data to arrival_01_15_2022.csv\n",
      "Processing 01/16/2022\n",
      "Saved data to arrival_01_16_2022.csv\n",
      "Processing 01/17/2022\n",
      "Saved data to arrival_01_17_2022.csv\n",
      "Processing 01/18/2022\n",
      "Saved data to arrival_01_18_2022.csv\n",
      "Processing 01/19/2022\n",
      "Saved data to arrival_01_19_2022.csv\n",
      "Processing 01/20/2022\n",
      "Saved data to arrival_01_20_2022.csv\n",
      "Processing 01/21/2022\n",
      "Saved data to arrival_01_21_2022.csv\n",
      "Processing 01/22/2022\n",
      "Saved data to arrival_01_22_2022.csv\n",
      "Processing 01/23/2022\n",
      "Saved data to arrival_01_23_2022.csv\n",
      "Processing 01/24/2022\n",
      "Saved data to arrival_01_24_2022.csv\n",
      "Processing 01/25/2022\n",
      "Saved data to arrival_01_25_2022.csv\n",
      "Processing 01/26/2022\n",
      "Saved data to arrival_01_26_2022.csv\n",
      "Processing 01/27/2022\n",
      "Saved data to arrival_01_27_2022.csv\n",
      "Processing 01/28/2022\n",
      "Saved data to arrival_01_28_2022.csv\n",
      "Processing 01/29/2022\n",
      "Saved data to arrival_01_29_2022.csv\n",
      "Processing 01/30/2022\n",
      "Saved data to arrival_01_30_2022.csv\n",
      "Processing 01/31/2022\n",
      "Saved data to arrival_01_31_2022.csv\n",
      "Processing 02/01/2022\n",
      "Saved data to arrival_02_01_2022.csv\n",
      "Processing 02/02/2022\n",
      "Saved data to arrival_02_02_2022.csv\n",
      "Processing 02/03/2022\n",
      "Saved data to arrival_02_03_2022.csv\n",
      "Processing 02/04/2022\n",
      "Saved data to arrival_02_04_2022.csv\n",
      "Processing 02/05/2022\n",
      "Saved data to arrival_02_05_2022.csv\n",
      "Processing 02/06/2022\n",
      "Saved data to arrival_02_06_2022.csv\n",
      "Processing 02/07/2022\n",
      "Saved data to arrival_02_07_2022.csv\n",
      "Processing 02/08/2022\n",
      "Saved data to arrival_02_08_2022.csv\n",
      "Processing 02/09/2022\n",
      "Saved data to arrival_02_09_2022.csv\n",
      "Processing 02/10/2022\n",
      "Saved data to arrival_02_10_2022.csv\n",
      "Processing 02/11/2022\n",
      "Saved data to arrival_02_11_2022.csv\n",
      "Processing 02/12/2022\n",
      "Saved data to arrival_02_12_2022.csv\n",
      "Processing 02/13/2022\n",
      "Saved data to arrival_02_13_2022.csv\n",
      "Processing 02/14/2022\n",
      "Saved data to arrival_02_14_2022.csv\n",
      "Processing 02/15/2022\n",
      "Saved data to arrival_02_15_2022.csv\n",
      "Processing 02/16/2022\n",
      "Saved data to arrival_02_16_2022.csv\n",
      "Processing 02/17/2022\n",
      "Saved data to arrival_02_17_2022.csv\n",
      "Processing 02/18/2022\n",
      "Saved data to arrival_02_18_2022.csv\n",
      "Processing 02/19/2022\n",
      "Saved data to arrival_02_19_2022.csv\n",
      "Processing 02/20/2022\n",
      "Saved data to arrival_02_20_2022.csv\n",
      "Processing 02/21/2022\n",
      "Saved data to arrival_02_21_2022.csv\n",
      "Processing 02/22/2022\n",
      "Saved data to arrival_02_22_2022.csv\n",
      "Processing 02/23/2022\n",
      "Saved data to arrival_02_23_2022.csv\n",
      "Processing 02/24/2022\n",
      "Saved data to arrival_02_24_2022.csv\n",
      "Processing 02/25/2022\n",
      "Saved data to arrival_02_25_2022.csv\n",
      "Processing 02/26/2022\n",
      "Saved data to arrival_02_26_2022.csv\n",
      "Processing 02/27/2022\n",
      "Saved data to arrival_02_27_2022.csv\n",
      "Processing 02/28/2022\n",
      "Saved data to arrival_02_28_2022.csv\n",
      "Processing 03/01/2022\n",
      "Saved data to arrival_03_01_2022.csv\n",
      "Processing 03/02/2022\n",
      "Saved data to arrival_03_02_2022.csv\n",
      "Processing 03/03/2022\n",
      "Saved data to arrival_03_03_2022.csv\n",
      "Processing 03/04/2022\n",
      "Saved data to arrival_03_04_2022.csv\n",
      "Processing 03/05/2022\n",
      "Saved data to arrival_03_05_2022.csv\n",
      "Processing 03/06/2022\n",
      "Saved data to arrival_03_06_2022.csv\n",
      "Processing 03/07/2022\n",
      "Saved data to arrival_03_07_2022.csv\n",
      "Processing 03/08/2022\n",
      "Saved data to arrival_03_08_2022.csv\n",
      "Processing 03/09/2022\n",
      "Saved data to arrival_03_09_2022.csv\n",
      "Processing 03/10/2022\n",
      "Saved data to arrival_03_10_2022.csv\n",
      "Processing 03/11/2022\n",
      "Saved data to arrival_03_11_2022.csv\n",
      "Processing 03/12/2022\n",
      "Saved data to arrival_03_12_2022.csv\n",
      "Processing 03/13/2022\n",
      "Saved data to arrival_03_13_2022.csv\n",
      "Processing 03/14/2022\n",
      "Saved data to arrival_03_14_2022.csv\n",
      "Processing 03/15/2022\n",
      "Saved data to arrival_03_15_2022.csv\n",
      "Processing 03/16/2022\n",
      "Saved data to arrival_03_16_2022.csv\n",
      "Processing 03/17/2022\n",
      "Saved data to arrival_03_17_2022.csv\n",
      "Processing 03/18/2022\n",
      "Saved data to arrival_03_18_2022.csv\n",
      "Processing 03/19/2022\n",
      "Saved data to arrival_03_19_2022.csv\n",
      "Processing 03/20/2022\n",
      "Saved data to arrival_03_20_2022.csv\n",
      "Processing 03/21/2022\n",
      "Saved data to arrival_03_21_2022.csv\n",
      "Processing 03/22/2022\n",
      "Saved data to arrival_03_22_2022.csv\n",
      "Processing 03/23/2022\n",
      "Saved data to arrival_03_23_2022.csv\n",
      "Processing 03/24/2022\n",
      "Saved data to arrival_03_24_2022.csv\n",
      "Processing 03/25/2022\n",
      "Saved data to arrival_03_25_2022.csv\n",
      "Processing 03/26/2022\n",
      "Saved data to arrival_03_26_2022.csv\n",
      "Processing 03/27/2022\n",
      "Saved data to arrival_03_27_2022.csv\n",
      "Processing 03/28/2022\n",
      "Saved data to arrival_03_28_2022.csv\n",
      "Processing 03/29/2022\n",
      "Saved data to arrival_03_29_2022.csv\n",
      "Processing 03/30/2022\n",
      "Saved data to arrival_03_30_2022.csv\n",
      "Processing 03/31/2022\n",
      "Saved data to arrival_03_31_2022.csv\n",
      "Processing 04/01/2022\n",
      "Saved data to arrival_04_01_2022.csv\n",
      "Processing 04/02/2022\n",
      "Saved data to arrival_04_02_2022.csv\n",
      "Processing 04/03/2022\n",
      "Saved data to arrival_04_03_2022.csv\n",
      "Processing 04/04/2022\n",
      "Saved data to arrival_04_04_2022.csv\n",
      "Processing 04/05/2022\n",
      "Saved data to arrival_04_05_2022.csv\n",
      "Processing 04/06/2022\n",
      "Saved data to arrival_04_06_2022.csv\n",
      "Processing 04/07/2022\n",
      "Saved data to arrival_04_07_2022.csv\n",
      "Processing 04/08/2022\n",
      "Saved data to arrival_04_08_2022.csv\n",
      "Processing 04/09/2022\n",
      "Saved data to arrival_04_09_2022.csv\n",
      "Processing 04/10/2022\n",
      "Saved data to arrival_04_10_2022.csv\n",
      "Processing 04/11/2022\n",
      "Saved data to arrival_04_11_2022.csv\n",
      "Processing 04/12/2022\n",
      "Saved data to arrival_04_12_2022.csv\n",
      "Processing 04/13/2022\n",
      "Saved data to arrival_04_13_2022.csv\n",
      "Processing 04/14/2022\n",
      "Saved data to arrival_04_14_2022.csv\n",
      "Processing 04/15/2022\n",
      "Saved data to arrival_04_15_2022.csv\n",
      "Processing 04/16/2022\n",
      "Saved data to arrival_04_16_2022.csv\n",
      "Processing 04/17/2022\n",
      "Saved data to arrival_04_17_2022.csv\n",
      "Processing 04/18/2022\n",
      "Saved data to arrival_04_18_2022.csv\n",
      "Processing 04/19/2022\n",
      "Saved data to arrival_04_19_2022.csv\n",
      "Processing 04/20/2022\n",
      "Saved data to arrival_04_20_2022.csv\n",
      "Processing 04/21/2022\n",
      "Saved data to arrival_04_21_2022.csv\n",
      "Processing 04/22/2022\n",
      "Saved data to arrival_04_22_2022.csv\n",
      "Processing 04/23/2022\n",
      "Saved data to arrival_04_23_2022.csv\n",
      "Processing 04/24/2022\n",
      "Saved data to arrival_04_24_2022.csv\n",
      "Processing 04/25/2022\n",
      "Saved data to arrival_04_25_2022.csv\n",
      "Processing 04/26/2022\n",
      "Saved data to arrival_04_26_2022.csv\n",
      "Processing 04/27/2022\n",
      "Saved data to arrival_04_27_2022.csv\n",
      "Processing 04/28/2022\n",
      "Saved data to arrival_04_28_2022.csv\n",
      "Processing 04/29/2022\n",
      "Saved data to arrival_04_29_2022.csv\n",
      "Processing 04/30/2022\n",
      "Saved data to arrival_04_30_2022.csv\n",
      "Processing 05/01/2022\n",
      "Saved data to arrival_05_01_2022.csv\n",
      "Processing 05/02/2022\n",
      "Saved data to arrival_05_02_2022.csv\n",
      "Processing 05/03/2022\n",
      "Saved data to arrival_05_03_2022.csv\n",
      "Processing 05/04/2022\n",
      "Saved data to arrival_05_04_2022.csv\n",
      "Processing 05/05/2022\n",
      "Saved data to arrival_05_05_2022.csv\n",
      "Processing 05/06/2022\n",
      "Saved data to arrival_05_06_2022.csv\n",
      "Processing 05/07/2022\n",
      "Saved data to arrival_05_07_2022.csv\n",
      "Processing 05/08/2022\n",
      "Saved data to arrival_05_08_2022.csv\n",
      "Processing 05/09/2022\n",
      "Saved data to arrival_05_09_2022.csv\n",
      "Processing 05/10/2022\n",
      "Saved data to arrival_05_10_2022.csv\n",
      "Processing 05/11/2022\n",
      "Saved data to arrival_05_11_2022.csv\n",
      "Processing 05/12/2022\n",
      "Saved data to arrival_05_12_2022.csv\n",
      "Processing 05/13/2022\n",
      "Saved data to arrival_05_13_2022.csv\n",
      "Processing 05/14/2022\n",
      "Saved data to arrival_05_14_2022.csv\n",
      "Processing 05/15/2022\n",
      "Saved data to arrival_05_15_2022.csv\n",
      "Processing 05/16/2022\n",
      "Saved data to arrival_05_16_2022.csv\n",
      "Processing 05/17/2022\n",
      "Saved data to arrival_05_17_2022.csv\n",
      "Processing 05/18/2022\n",
      "Saved data to arrival_05_18_2022.csv\n",
      "Processing 05/19/2022\n",
      "Saved data to arrival_05_19_2022.csv\n",
      "Processing 05/20/2022\n",
      "Saved data to arrival_05_20_2022.csv\n",
      "Processing 05/21/2022\n",
      "Saved data to arrival_05_21_2022.csv\n",
      "Processing 05/22/2022\n",
      "Saved data to arrival_05_22_2022.csv\n",
      "Processing 05/23/2022\n",
      "Saved data to arrival_05_23_2022.csv\n",
      "Processing 05/24/2022\n",
      "Saved data to arrival_05_24_2022.csv\n",
      "Processing 05/25/2022\n",
      "Saved data to arrival_05_25_2022.csv\n",
      "Processing 05/26/2022\n",
      "Saved data to arrival_05_26_2022.csv\n",
      "Processing 05/27/2022\n",
      "Saved data to arrival_05_27_2022.csv\n",
      "Processing 05/28/2022\n",
      "Saved data to arrival_05_28_2022.csv\n",
      "Processing 05/29/2022\n",
      "Saved data to arrival_05_29_2022.csv\n",
      "Processing 05/30/2022\n",
      "Saved data to arrival_05_30_2022.csv\n",
      "Processing 05/31/2022\n",
      "Saved data to arrival_05_31_2022.csv\n",
      "Processing 06/01/2022\n",
      "Saved data to arrival_06_01_2022.csv\n",
      "Processing 06/02/2022\n",
      "Saved data to arrival_06_02_2022.csv\n",
      "Processing 06/03/2022\n",
      "Saved data to arrival_06_03_2022.csv\n",
      "Processing 06/04/2022\n",
      "Saved data to arrival_06_04_2022.csv\n",
      "Processing 06/05/2022\n",
      "Saved data to arrival_06_05_2022.csv\n",
      "Processing 06/06/2022\n",
      "Saved data to arrival_06_06_2022.csv\n",
      "Processing 06/07/2022\n",
      "Saved data to arrival_06_07_2022.csv\n",
      "Processing 06/08/2022\n",
      "Saved data to arrival_06_08_2022.csv\n",
      "Processing 06/09/2022\n",
      "Saved data to arrival_06_09_2022.csv\n",
      "Processing 06/10/2022\n",
      "Saved data to arrival_06_10_2022.csv\n",
      "Processing 06/11/2022\n",
      "Saved data to arrival_06_11_2022.csv\n",
      "Processing 06/12/2022\n",
      "Saved data to arrival_06_12_2022.csv\n",
      "Processing 06/13/2022\n",
      "Saved data to arrival_06_13_2022.csv\n",
      "Processing 06/14/2022\n",
      "Saved data to arrival_06_14_2022.csv\n",
      "Processing 06/15/2022\n",
      "Saved data to arrival_06_15_2022.csv\n",
      "Processing 06/16/2022\n",
      "Saved data to arrival_06_16_2022.csv\n",
      "Processing 06/17/2022\n",
      "Saved data to arrival_06_17_2022.csv\n",
      "Processing 06/18/2022\n",
      "Saved data to arrival_06_18_2022.csv\n",
      "Processing 06/19/2022\n",
      "Saved data to arrival_06_19_2022.csv\n",
      "Processing 06/20/2022\n",
      "Saved data to arrival_06_20_2022.csv\n",
      "Processing 06/21/2022\n",
      "Saved data to arrival_06_21_2022.csv\n",
      "Processing 06/22/2022\n",
      "Saved data to arrival_06_22_2022.csv\n",
      "Processing 06/23/2022\n",
      "Saved data to arrival_06_23_2022.csv\n",
      "Processing 06/24/2022\n",
      "Saved data to arrival_06_24_2022.csv\n",
      "Processing 06/25/2022\n",
      "Saved data to arrival_06_25_2022.csv\n",
      "Processing 06/26/2022\n",
      "Saved data to arrival_06_26_2022.csv\n",
      "Processing 06/27/2022\n",
      "Saved data to arrival_06_27_2022.csv\n",
      "Processing 06/28/2022\n",
      "Saved data to arrival_06_28_2022.csv\n",
      "Processing 06/29/2022\n",
      "Saved data to arrival_06_29_2022.csv\n",
      "Processing 06/30/2022\n",
      "Saved data to arrival_06_30_2022.csv\n",
      "Processing 07/01/2022\n",
      "Saved data to arrival_07_01_2022.csv\n",
      "Processing 07/02/2022\n",
      "Saved data to arrival_07_02_2022.csv\n",
      "Processing 07/03/2022\n",
      "Saved data to arrival_07_03_2022.csv\n",
      "Processing 07/04/2022\n",
      "Saved data to arrival_07_04_2022.csv\n",
      "Processing 07/05/2022\n",
      "Saved data to arrival_07_05_2022.csv\n",
      "Processing 07/06/2022\n",
      "Saved data to arrival_07_06_2022.csv\n",
      "Processing 07/07/2022\n",
      "Saved data to arrival_07_07_2022.csv\n",
      "Processing 07/08/2022\n",
      "Saved data to arrival_07_08_2022.csv\n",
      "Processing 07/09/2022\n",
      "Saved data to arrival_07_09_2022.csv\n",
      "Processing 07/10/2022\n",
      "Saved data to arrival_07_10_2022.csv\n",
      "Processing 07/11/2022\n",
      "Saved data to arrival_07_11_2022.csv\n",
      "Processing 07/12/2022\n",
      "Saved data to arrival_07_12_2022.csv\n",
      "Processing 07/13/2022\n",
      "Saved data to arrival_07_13_2022.csv\n",
      "Processing 07/14/2022\n",
      "Saved data to arrival_07_14_2022.csv\n",
      "Processing 07/15/2022\n",
      "Saved data to arrival_07_15_2022.csv\n",
      "Processing 07/16/2022\n",
      "Saved data to arrival_07_16_2022.csv\n",
      "Processing 07/17/2022\n",
      "Saved data to arrival_07_17_2022.csv\n",
      "Processing 07/18/2022\n",
      "Saved data to arrival_07_18_2022.csv\n",
      "Processing 07/19/2022\n",
      "Saved data to arrival_07_19_2022.csv\n",
      "Processing 07/20/2022\n",
      "Saved data to arrival_07_20_2022.csv\n",
      "Processing 07/21/2022\n",
      "Saved data to arrival_07_21_2022.csv\n",
      "Processing 07/22/2022\n",
      "Saved data to arrival_07_22_2022.csv\n",
      "Processing 07/23/2022\n",
      "Saved data to arrival_07_23_2022.csv\n",
      "Processing 07/24/2022\n",
      "Saved data to arrival_07_24_2022.csv\n",
      "Processing 07/25/2022\n",
      "Saved data to arrival_07_25_2022.csv\n",
      "Processing 07/26/2022\n",
      "Saved data to arrival_07_26_2022.csv\n",
      "Processing 07/27/2022\n",
      "Saved data to arrival_07_27_2022.csv\n",
      "Processing 07/28/2022\n",
      "Saved data to arrival_07_28_2022.csv\n",
      "Processing 07/29/2022\n",
      "Saved data to arrival_07_29_2022.csv\n",
      "Processing 07/30/2022\n",
      "Saved data to arrival_07_30_2022.csv\n",
      "Processing 07/31/2022\n",
      "Saved data to arrival_07_31_2022.csv\n",
      "Processing 08/01/2022\n",
      "Saved data to arrival_08_01_2022.csv\n",
      "Processing 08/02/2022\n",
      "Saved data to arrival_08_02_2022.csv\n",
      "Processing 08/03/2022\n",
      "Saved data to arrival_08_03_2022.csv\n",
      "Processing 08/04/2022\n",
      "Saved data to arrival_08_04_2022.csv\n",
      "Processing 08/05/2022\n",
      "Saved data to arrival_08_05_2022.csv\n",
      "Processing 08/06/2022\n",
      "Saved data to arrival_08_06_2022.csv\n",
      "Processing 08/07/2022\n",
      "Saved data to arrival_08_07_2022.csv\n",
      "Processing 08/08/2022\n",
      "Saved data to arrival_08_08_2022.csv\n",
      "Processing 08/09/2022\n",
      "Saved data to arrival_08_09_2022.csv\n",
      "Processing 08/10/2022\n",
      "Saved data to arrival_08_10_2022.csv\n",
      "Processing 08/11/2022\n",
      "Saved data to arrival_08_11_2022.csv\n",
      "Processing 08/12/2022\n",
      "Saved data to arrival_08_12_2022.csv\n",
      "Processing 08/13/2022\n",
      "Saved data to arrival_08_13_2022.csv\n",
      "Processing 08/14/2022\n",
      "Saved data to arrival_08_14_2022.csv\n",
      "Processing 08/15/2022\n",
      "Saved data to arrival_08_15_2022.csv\n",
      "Processing 08/16/2022\n",
      "Saved data to arrival_08_16_2022.csv\n",
      "Processing 08/17/2022\n",
      "Saved data to arrival_08_17_2022.csv\n",
      "Processing 08/18/2022\n",
      "Saved data to arrival_08_18_2022.csv\n",
      "Processing 08/19/2022\n",
      "Saved data to arrival_08_19_2022.csv\n",
      "Processing 08/20/2022\n",
      "Saved data to arrival_08_20_2022.csv\n",
      "Processing 08/21/2022\n",
      "Saved data to arrival_08_21_2022.csv\n",
      "Processing 08/22/2022\n",
      "Saved data to arrival_08_22_2022.csv\n",
      "Processing 08/23/2022\n",
      "Saved data to arrival_08_23_2022.csv\n",
      "Processing 08/24/2022\n",
      "Saved data to arrival_08_24_2022.csv\n",
      "Processing 08/25/2022\n",
      "Saved data to arrival_08_25_2022.csv\n",
      "Processing 08/26/2022\n",
      "Saved data to arrival_08_26_2022.csv\n",
      "Processing 08/27/2022\n",
      "Saved data to arrival_08_27_2022.csv\n",
      "Processing 08/28/2022\n",
      "Saved data to arrival_08_28_2022.csv\n",
      "Processing 08/29/2022\n",
      "Saved data to arrival_08_29_2022.csv\n",
      "Processing 08/30/2022\n",
      "Saved data to arrival_08_30_2022.csv\n",
      "Processing 08/31/2022\n",
      "Saved data to arrival_08_31_2022.csv\n",
      "Processing 09/01/2022\n",
      "Saved data to arrival_09_01_2022.csv\n",
      "Processing 09/02/2022\n",
      "Saved data to arrival_09_02_2022.csv\n",
      "Processing 09/03/2022\n",
      "Saved data to arrival_09_03_2022.csv\n",
      "Processing 09/04/2022\n",
      "Saved data to arrival_09_04_2022.csv\n",
      "Processing 09/05/2022\n",
      "Saved data to arrival_09_05_2022.csv\n",
      "Processing 09/06/2022\n",
      "Saved data to arrival_09_06_2022.csv\n",
      "Processing 09/07/2022\n",
      "Saved data to arrival_09_07_2022.csv\n",
      "Processing 09/08/2022\n",
      "Saved data to arrival_09_08_2022.csv\n",
      "Processing 09/09/2022\n",
      "Saved data to arrival_09_09_2022.csv\n",
      "Processing 09/10/2022\n",
      "Saved data to arrival_09_10_2022.csv\n",
      "Processing 09/11/2022\n",
      "Saved data to arrival_09_11_2022.csv\n",
      "Processing 09/12/2022\n",
      "Saved data to arrival_09_12_2022.csv\n",
      "Processing 09/13/2022\n",
      "Saved data to arrival_09_13_2022.csv\n",
      "Processing 09/14/2022\n",
      "Saved data to arrival_09_14_2022.csv\n",
      "Processing 09/15/2022\n",
      "Saved data to arrival_09_15_2022.csv\n",
      "Processing 09/16/2022\n",
      "Saved data to arrival_09_16_2022.csv\n",
      "Processing 09/17/2022\n",
      "Saved data to arrival_09_17_2022.csv\n",
      "Processing 09/18/2022\n",
      "Saved data to arrival_09_18_2022.csv\n",
      "Processing 09/19/2022\n",
      "Saved data to arrival_09_19_2022.csv\n",
      "Processing 09/20/2022\n",
      "Saved data to arrival_09_20_2022.csv\n",
      "Processing 09/21/2022\n",
      "Saved data to arrival_09_21_2022.csv\n",
      "Processing 09/22/2022\n",
      "Saved data to arrival_09_22_2022.csv\n",
      "Processing 09/23/2022\n",
      "Saved data to arrival_09_23_2022.csv\n",
      "Processing 09/24/2022\n",
      "Saved data to arrival_09_24_2022.csv\n",
      "Processing 09/25/2022\n",
      "Saved data to arrival_09_25_2022.csv\n",
      "Processing 09/26/2022\n",
      "Saved data to arrival_09_26_2022.csv\n",
      "Processing 09/27/2022\n",
      "Saved data to arrival_09_27_2022.csv\n",
      "Processing 09/28/2022\n",
      "Saved data to arrival_09_28_2022.csv\n",
      "Processing 09/29/2022\n",
      "Saved data to arrival_09_29_2022.csv\n",
      "Processing 09/30/2022\n",
      "Saved data to arrival_09_30_2022.csv\n",
      "Processing 10/01/2022\n",
      "Saved data to arrival_10_01_2022.csv\n",
      "Processing 10/02/2022\n",
      "Saved data to arrival_10_02_2022.csv\n",
      "Processing 10/03/2022\n",
      "Saved data to arrival_10_03_2022.csv\n",
      "Processing 10/04/2022\n",
      "Saved data to arrival_10_04_2022.csv\n",
      "Processing 10/05/2022\n",
      "Saved data to arrival_10_05_2022.csv\n",
      "Processing 10/06/2022\n",
      "Saved data to arrival_10_06_2022.csv\n",
      "Processing 10/07/2022\n",
      "Saved data to arrival_10_07_2022.csv\n",
      "Processing 10/08/2022\n",
      "Saved data to arrival_10_08_2022.csv\n",
      "Processing 10/09/2022\n",
      "Saved data to arrival_10_09_2022.csv\n",
      "Processing 10/10/2022\n",
      "Saved data to arrival_10_10_2022.csv\n",
      "Processing 10/11/2022\n",
      "Saved data to arrival_10_11_2022.csv\n",
      "Processing 10/12/2022\n",
      "Saved data to arrival_10_12_2022.csv\n",
      "Processing 10/13/2022\n",
      "Saved data to arrival_10_13_2022.csv\n",
      "Processing 10/14/2022\n",
      "Saved data to arrival_10_14_2022.csv\n",
      "Processing 10/15/2022\n",
      "Saved data to arrival_10_15_2022.csv\n",
      "Processing 10/16/2022\n",
      "Saved data to arrival_10_16_2022.csv\n",
      "Processing 10/17/2022\n",
      "Saved data to arrival_10_17_2022.csv\n",
      "Processing 10/18/2022\n",
      "Saved data to arrival_10_18_2022.csv\n",
      "Processing 10/19/2022\n",
      "Saved data to arrival_10_19_2022.csv\n",
      "Processing 10/20/2022\n",
      "Saved data to arrival_10_20_2022.csv\n",
      "Processing 10/21/2022\n",
      "Saved data to arrival_10_21_2022.csv\n",
      "Processing 10/22/2022\n",
      "Saved data to arrival_10_22_2022.csv\n",
      "Processing 10/23/2022\n",
      "Saved data to arrival_10_23_2022.csv\n",
      "Processing 10/24/2022\n",
      "Saved data to arrival_10_24_2022.csv\n",
      "Processing 10/25/2022\n",
      "Saved data to arrival_10_25_2022.csv\n",
      "Processing 10/26/2022\n",
      "Saved data to arrival_10_26_2022.csv\n",
      "Processing 10/27/2022\n",
      "Saved data to arrival_10_27_2022.csv\n",
      "Processing 10/28/2022\n",
      "Saved data to arrival_10_28_2022.csv\n",
      "Processing 10/29/2022\n",
      "Saved data to arrival_10_29_2022.csv\n",
      "Processing 10/30/2022\n",
      "Saved data to arrival_10_30_2022.csv\n",
      "Processing 10/31/2022\n",
      "Saved data to arrival_10_31_2022.csv\n",
      "Processing 11/01/2022\n",
      "Saved data to arrival_11_01_2022.csv\n",
      "Processing 11/02/2022\n",
      "Saved data to arrival_11_02_2022.csv\n",
      "Processing 11/03/2022\n",
      "Saved data to arrival_11_03_2022.csv\n",
      "Processing 11/04/2022\n",
      "Saved data to arrival_11_04_2022.csv\n",
      "Processing 11/05/2022\n",
      "Saved data to arrival_11_05_2022.csv\n",
      "Processing 11/06/2022\n",
      "Saved data to arrival_11_06_2022.csv\n",
      "Processing 11/07/2022\n",
      "Saved data to arrival_11_07_2022.csv\n",
      "Processing 11/08/2022\n",
      "Saved data to arrival_11_08_2022.csv\n",
      "Processing 11/09/2022\n",
      "Saved data to arrival_11_09_2022.csv\n",
      "Processing 11/10/2022\n",
      "Saved data to arrival_11_10_2022.csv\n",
      "Processing 11/11/2022\n",
      "Saved data to arrival_11_11_2022.csv\n",
      "Processing 11/12/2022\n",
      "Saved data to arrival_11_12_2022.csv\n",
      "Processing 11/13/2022\n",
      "Saved data to arrival_11_13_2022.csv\n",
      "Processing 11/14/2022\n",
      "Saved data to arrival_11_14_2022.csv\n",
      "Processing 11/15/2022\n",
      "Saved data to arrival_11_15_2022.csv\n",
      "Processing 11/16/2022\n",
      "Saved data to arrival_11_16_2022.csv\n",
      "Processing 11/17/2022\n",
      "Saved data to arrival_11_17_2022.csv\n",
      "Processing 11/18/2022\n",
      "Saved data to arrival_11_18_2022.csv\n",
      "Processing 11/19/2022\n",
      "Saved data to arrival_11_19_2022.csv\n",
      "Processing 11/20/2022\n",
      "Saved data to arrival_11_20_2022.csv\n",
      "Processing 11/21/2022\n",
      "Saved data to arrival_11_21_2022.csv\n",
      "Processing 11/22/2022\n",
      "Saved data to arrival_11_22_2022.csv\n",
      "Processing 11/23/2022\n",
      "Saved data to arrival_11_23_2022.csv\n",
      "Processing 11/24/2022\n",
      "Saved data to arrival_11_24_2022.csv\n",
      "Processing 11/25/2022\n",
      "Saved data to arrival_11_25_2022.csv\n",
      "Processing 11/26/2022\n",
      "Saved data to arrival_11_26_2022.csv\n",
      "Processing 11/27/2022\n",
      "Saved data to arrival_11_27_2022.csv\n",
      "Processing 11/28/2022\n",
      "Saved data to arrival_11_28_2022.csv\n",
      "Processing 11/29/2022\n",
      "Saved data to arrival_11_29_2022.csv\n",
      "Processing 11/30/2022\n",
      "Saved data to arrival_11_30_2022.csv\n",
      "Processing 12/01/2022\n",
      "Saved data to arrival_12_01_2022.csv\n",
      "Processing 12/02/2022\n",
      "Saved data to arrival_12_02_2022.csv\n",
      "Processing 12/03/2022\n",
      "Saved data to arrival_12_03_2022.csv\n",
      "Processing 12/04/2022\n",
      "Saved data to arrival_12_04_2022.csv\n",
      "Processing 12/05/2022\n",
      "Saved data to arrival_12_05_2022.csv\n",
      "Processing 12/06/2022\n",
      "Saved data to arrival_12_06_2022.csv\n",
      "Processing 12/07/2022\n",
      "Saved data to arrival_12_07_2022.csv\n",
      "Processing 12/08/2022\n",
      "Saved data to arrival_12_08_2022.csv\n",
      "Processing 12/09/2022\n",
      "Saved data to arrival_12_09_2022.csv\n",
      "Processing 12/10/2022\n",
      "Saved data to arrival_12_10_2022.csv\n",
      "Processing 12/11/2022\n",
      "Saved data to arrival_12_11_2022.csv\n",
      "Processing 12/12/2022\n",
      "Saved data to arrival_12_12_2022.csv\n",
      "Processing 12/13/2022\n",
      "Saved data to arrival_12_13_2022.csv\n",
      "Processing 12/14/2022\n",
      "Saved data to arrival_12_14_2022.csv\n",
      "Processing 12/15/2022\n",
      "Saved data to arrival_12_15_2022.csv\n",
      "Processing 12/16/2022\n",
      "Saved data to arrival_12_16_2022.csv\n",
      "Processing 12/17/2022\n",
      "Saved data to arrival_12_17_2022.csv\n",
      "Processing 12/18/2022\n",
      "Saved data to arrival_12_18_2022.csv\n",
      "Processing 12/19/2022\n",
      "Saved data to arrival_12_19_2022.csv\n",
      "Processing 12/20/2022\n",
      "Saved data to arrival_12_20_2022.csv\n",
      "Processing 12/21/2022\n",
      "Saved data to arrival_12_21_2022.csv\n",
      "Processing 12/22/2022\n",
      "Saved data to arrival_12_22_2022.csv\n",
      "Processing 12/23/2022\n",
      "Saved data to arrival_12_23_2022.csv\n",
      "Processing 12/24/2022\n",
      "Saved data to arrival_12_24_2022.csv\n",
      "Processing 12/25/2022\n",
      "Saved data to arrival_12_25_2022.csv\n",
      "Processing 12/26/2022\n",
      "Saved data to arrival_12_26_2022.csv\n",
      "Processing 12/27/2022\n",
      "Saved data to arrival_12_27_2022.csv\n",
      "Processing 12/28/2022\n",
      "Saved data to arrival_12_28_2022.csv\n",
      "Processing 12/29/2022\n",
      "Saved data to arrival_12_29_2022.csv\n",
      "Processing 12/30/2022\n",
      "Saved data to arrival_12_30_2022.csv\n",
      "Processing 12/31/2022\n",
      "Saved data to arrival_12_31_2022.csv\n",
      "Done with sincere extraction for January 2025!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "driver.get(\"https://kalimatimarket.gov.np/\")\n",
    "\n",
    "start_date = datetime.strptime('01/01/2022', '%m/%d/%Y')\n",
    "end_date = datetime.strptime('12/31/2022', '%m/%d/%Y')\n",
    "\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    target_date = current_date.strftime('%m/%d/%Y')\n",
    "    filename_date = target_date.replace('/', '_')\n",
    "    filename = f'arrival_{filename_date}.csv'\n",
    "    print(f\"Processing {target_date}\")\n",
    "\n",
    "    try:\n",
    "        # Find and set date input\n",
    "        date_input = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"input[type='text'], input[type='date']\")))\n",
    "        date_input.clear()\n",
    "        date_input.send_keys(target_date)\n",
    "\n",
    "        # Click the \"आगमन डाटा जाँच्नुहोस्\" button\n",
    "        arrival_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(),'मूल्यहरू जाँच गर्नुहोस्')]\")))\n",
    "        arrival_button.click()\n",
    "\n",
    "        # Wait up to 20 seconds for table to update (avoid stale table)\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"table\")))\n",
    "\n",
    "        # Now, RE-FIND all rows fresh for each loop\n",
    "        time.sleep(2)  # Give extra time for asynchronous JS data load\n",
    "\n",
    "        table_data = []\n",
    "        rows = driver.find_elements(By.CSS_SELECTOR, \"table tr\")  # <--- Fresh locate!\n",
    "        for row in rows:\n",
    "            cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            if cols:\n",
    "                table_data.append([col.text.strip() for col in cols])\n",
    "\n",
    "        # Check if there is any actual, meaningful data (not just empty rows)\n",
    "        data_exists = any(any(cell for cell in row) for row in table_data)\n",
    "        if data_exists:\n",
    "            with open(filename, \"w\", newline='', encoding='utf-8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                for row in table_data:\n",
    "                    writer.writerow(row)\n",
    "            print(f\"Saved data to {filename}\")\n",
    "        else:\n",
    "            print(f\"No arrival data for {target_date} (table was blank or only headers)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on {target_date}: {e}\")\n",
    "\n",
    "    current_date += timedelta(days=1)\n",
    "    time.sleep(1)\n",
    "\n",
    "driver.quit()\n",
    "print(\"Done with sincere extraction for January 2025!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ff0e09-7330-4c3f-a858-620e20eb19d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Working folder: D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\n",
      "✅ Found 367 CSV files to merge\n",
      "✅ Merging completed successfully!\n",
      "💾 File saved as: D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\\arrival_2022_full.csv\n",
      "Final shape: (36212, 6)\n",
      "         Date             commodity    unit    minimum    maximum  \\\n",
      "0  2022-01-01  गोलभेडा ठूलो(भारतीय)    केजी  रू १०१.००  रू १०१.००   \n",
      "1  2022-01-01    गोलभेडा सानो(लोकल)  के.जी.   रू ४०.००   रू ५०.००   \n",
      "2  2022-01-01    गोलभेडा सानो(टनेल)   के जी   रू ५०.००   रू ६०.००   \n",
      "3  2022-01-01  गोलभेडा सानो(भारतीय)   के जी   रू ५५.००   रू ६५.००   \n",
      "4  2022-01-01    गोलभेडा सानो(तराई)   के जी   रू ६०.००   रू ७०.००   \n",
      "\n",
      "  average_price  \n",
      "0     रू १०१.००  \n",
      "1      रू ४५.००  \n",
      "2      रू ५५.००  \n",
      "3      रू ६०.००  \n",
      "4      रू ६५.००  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20552\\257274747.py:37: DtypeWarning: Columns (2,3,4,8,10,15,18,20,21,24,26,27,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 1: Automatically detect current working directory\n",
    "# ---------------------------------------------------------------\n",
    "folder = os.getcwd()\n",
    "print(f\"📂 Working folder: {folder}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 2: Find all CSV files starting with 'arrival_'\n",
    "# ---------------------------------------------------------------\n",
    "csv_files = sorted(glob(os.path.join(folder, \"arrival_*.csv\")))\n",
    "\n",
    "print(f\"✅ Found {len(csv_files)} CSV files to merge\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 3: Read, clean, and standardize each CSV\n",
    "# ---------------------------------------------------------------\n",
    "merged_data = []\n",
    "\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        # Extract date from filename, e.g. 'arrival_02_15_2022.csv' → '2022-02-15'\n",
    "        basename = os.path.basename(file)\n",
    "        date_str = basename.replace(\"arrival_\", \"\").replace(\".csv\", \"\")\n",
    "        # handle formats like arrival_1_2_2022.csv as well\n",
    "        parts = date_str.split(\"_\")\n",
    "        if len(parts) == 3:\n",
    "            month, day, year = parts\n",
    "            formatted_date = f\"{year}-{int(month):02d}-{int(day):02d}\"\n",
    "        else:\n",
    "            formatted_date = None\n",
    "        \n",
    "        # Read CSV\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        # Standardize columns (in case names vary or missing)\n",
    "        df.columns = [col.strip().lower() for col in df.columns]\n",
    "        \n",
    "        # Select only first 6 columns if extra exist\n",
    "        df = df.iloc[:, :6]\n",
    "        \n",
    "        # Assign correct column names\n",
    "        df.columns = ['commodity', 'unit', 'minimum', 'maximum', 'average_price', 'extra'][:len(df.columns)]\n",
    "        \n",
    "        # Ensure required columns exist (fill missing)\n",
    "        for col in ['commodity', 'unit', 'minimum', 'maximum', 'average_price']:\n",
    "            if col not in df.columns:\n",
    "                df[col] = None\n",
    "        \n",
    "        # Add Date column\n",
    "        df['Date'] = formatted_date\n",
    "        \n",
    "        # Reorder columns\n",
    "        df = df[['Date', 'commodity', 'unit', 'minimum', 'maximum', 'average_price']]\n",
    "        \n",
    "        # Append to list\n",
    "        merged_data.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {file}: {e}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 4: Merge all DataFrames\n",
    "# ---------------------------------------------------------------\n",
    "final_df = pd.concat(merged_data, ignore_index=True)\n",
    "final_df = final_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 5: Save merged CSV\n",
    "# ---------------------------------------------------------------\n",
    "output_file = os.path.join(folder, \"arrival_2022_full.csv\")\n",
    "final_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"✅ Merging completed successfully!\")\n",
    "print(f\"💾 File saved as: {output_file}\")\n",
    "print(\"Final shape:\", final_df.shape)\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d9027e-1290-43d3-8d3a-a56c612aeb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Current working directory: D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\n",
      "✅ Found 366 CSV files to merge\n",
      "⚠️ Error reading D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\\arrival_02_26_2022.csv: \"['unit', 'minimum', 'maximum', 'average_price'] not in index\"\n",
      "⚠️ Error reading D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\\arrival_03_04_2022.csv: \"['unit', 'minimum', 'maximum', 'average_price'] not in index\"\n",
      "⚠️ Error reading D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\\arrival_05_13_2022.csv: \"['unit', 'minimum', 'maximum', 'average_price'] not in index\"\n",
      "⚠️ Error reading D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\\arrival_11_20_2022.csv: \"['unit', 'minimum', 'maximum', 'average_price'] not in index\"\n",
      "⚠️ Error reading D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\\arrival_merge.csv: \"['average_price'] not in index\"\n",
      "✅ Merge complete!\n",
      "💾 Saved as: D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\\arrival_2022_full.csv\n",
      "Final shape: (35084, 6)\n",
      "         Date             commodity    unit  minimum  maximum  average_price\n",
      "0  2022-01-01  गोलभेडा ठूलो(नेपाली)  के.जी.      NaN      NaN            NaN\n",
      "1  2022-01-01  गोलभेडा ठूलो(भारतीय)    केजी      NaN      NaN            NaN\n",
      "2  2022-01-01    गोलभेडा सानो(लोकल)  के.जी.      NaN      NaN            NaN\n",
      "3  2022-01-01    गोलभेडा सानो(टनेल)   के जी      NaN      NaN            NaN\n",
      "4  2022-01-01  गोलभेडा सानो(भारतीय)   के जी      NaN      NaN            NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 1: Detect current working directory\n",
    "# ---------------------------------------------------------------\n",
    "folder = os.getcwd()\n",
    "print(f\"📂 Current working directory: {folder}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 2: Get all arrival CSV files\n",
    "# ---------------------------------------------------------------\n",
    "csv_files = sorted(glob(os.path.join(folder, \"arrival_*.csv\")))\n",
    "print(f\"✅ Found {len(csv_files)} CSV files to merge\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 3: Define correct column names\n",
    "# ---------------------------------------------------------------\n",
    "columns = ['commodity', 'unit', 'minimum', 'maximum', 'average_price']\n",
    "\n",
    "merged_data = []\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 4: Read each file (no header) and add date from filename\n",
    "# ---------------------------------------------------------------\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        # Extract date from filename, e.g. \"arrival_03_15_2022.csv\" → \"2022-03-15\"\n",
    "        basename = os.path.basename(file)\n",
    "        date_str = basename.replace(\"arrival_\", \"\").replace(\".csv\", \"\")\n",
    "        parts = date_str.split(\"_\")\n",
    "        if len(parts) == 3:\n",
    "            month, day, year = parts\n",
    "            formatted_date = f\"{year}-{int(month):02d}-{int(day):02d}\"\n",
    "        else:\n",
    "            formatted_date = None\n",
    "\n",
    "        # Read CSV with no header\n",
    "        df = pd.read_csv(file, header=None)\n",
    "\n",
    "        # Assign column names manually\n",
    "        df.columns = columns[:len(df.columns)]\n",
    "\n",
    "        # Add Date column\n",
    "        df['Date'] = formatted_date\n",
    "\n",
    "        # Reorder columns (Date first)\n",
    "        df = df[['Date'] + columns]\n",
    "\n",
    "        merged_data.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {file}: {e}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 5: Merge all data into one DataFrame\n",
    "# ---------------------------------------------------------------\n",
    "final_df = pd.concat(merged_data, ignore_index=True)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 6: Clean & Save\n",
    "# ---------------------------------------------------------------\n",
    "final_df = final_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Convert numeric columns if needed\n",
    "for col in ['minimum', 'maximum', 'average_price']:\n",
    "    final_df[col] = pd.to_numeric(final_df[col], errors='coerce')\n",
    "\n",
    "# Save as single CSV\n",
    "output_file = os.path.join(folder, \"arrival_2022_full.csv\")\n",
    "final_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"✅ Merge complete!\")\n",
    "print(f\"💾 Saved as: {output_file}\")\n",
    "print(\"Final shape:\", final_df.shape)\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ba202fa-8dc2-4efb-a279-d05c71309d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Current working directory: D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\n",
      "✅ Found 365 CSV files to merge\n",
      "✅ Merge complete!\n",
      "💾 Saved as: D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\\arrival_2022_full.csv\n",
      "Final shape: (35088, 6)\n",
      "         Date              commodity    unit  minimum  maximum  average_price\n",
      "0  2022-01-01   गोलभेडा ठूलो(नेपाली)  के.जी.      NaN      NaN            NaN\n",
      "1  2022-01-01   गोलभेडा ठूलो(भारतीय)    केजी      NaN      NaN            NaN\n",
      "2  2022-01-01     गोलभेडा सानो(लोकल)  के.जी.      NaN      NaN            NaN\n",
      "3  2022-01-01     गोलभेडा सानो(टनेल)   के जी      NaN      NaN            NaN\n",
      "4  2022-01-01   गोलभेडा सानो(भारतीय)   के जी      NaN      NaN            NaN\n",
      "5  2022-01-01     गोलभेडा सानो(तराई)   के जी      NaN      NaN            NaN\n",
      "6  2022-01-01               आलु रातो  के.जी.      NaN      NaN            NaN\n",
      "7  2022-01-01       आलु रातो(भारतीय)   के जी      NaN      NaN            NaN\n",
      "8  2022-01-01               आलु सेतो  के.जी.      NaN      NaN            NaN\n",
      "9  2022-01-01  प्याज सुकेको (भारतीय)  के.जी.      NaN      NaN            NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 1: Working directory (your notebook folder)\n",
    "# ---------------------------------------------------------------\n",
    "folder = os.getcwd()\n",
    "print(f\"📂 Current working directory: {folder}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 2: Get all CSV files (skip already merged ones)\n",
    "# ---------------------------------------------------------------\n",
    "csv_files = sorted(glob(os.path.join(folder, \"arrival_*.csv\")))\n",
    "csv_files = [f for f in csv_files if \"merge\" not in f and \"full\" not in f]\n",
    "\n",
    "print(f\"✅ Found {len(csv_files)} CSV files to merge\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 3: Define standard column names\n",
    "# ---------------------------------------------------------------\n",
    "standard_cols = ['commodity', 'unit', 'minimum', 'maximum', 'average_price']\n",
    "\n",
    "merged_data = []\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 4: Loop through all files\n",
    "# ---------------------------------------------------------------\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        # Extract date from filename\n",
    "        basename = os.path.basename(file)\n",
    "        date_str = basename.replace(\"arrival_\", \"\").replace(\".csv\", \"\")\n",
    "        parts = date_str.split(\"_\")\n",
    "        if len(parts) == 3:\n",
    "            month, day, year = parts\n",
    "            formatted_date = f\"{year}-{int(month):02d}-{int(day):02d}\"\n",
    "        else:\n",
    "            formatted_date = None\n",
    "\n",
    "        # Try reading with flexible delimiters\n",
    "        try:\n",
    "            df = pd.read_csv(file, header=None, engine='python')\n",
    "        except:\n",
    "            df = pd.read_csv(file, header=None, delimiter=';', engine='python')\n",
    "        \n",
    "        # Drop completely empty columns\n",
    "        df = df.dropna(axis=1, how='all')\n",
    "        \n",
    "        # Keep only up to 5 columns (extra columns are garbage)\n",
    "        df = df.iloc[:, :5]\n",
    "\n",
    "        # Assign standard column names\n",
    "        df.columns = standard_cols[:len(df.columns)]\n",
    "\n",
    "        # Fill missing columns if file had fewer columns\n",
    "        for col in standard_cols:\n",
    "            if col not in df.columns:\n",
    "                df[col] = None\n",
    "\n",
    "        # Add date column\n",
    "        df['Date'] = formatted_date\n",
    "\n",
    "        # Reorder\n",
    "        df = df[['Date'] + standard_cols]\n",
    "\n",
    "        # Clean up whitespace in text columns\n",
    "        for col in ['commodity', 'unit']:\n",
    "            df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "        merged_data.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {file}: {e}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 5: Combine all data\n",
    "# ---------------------------------------------------------------\n",
    "final_df = pd.concat(merged_data, ignore_index=True)\n",
    "final_df = final_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Convert numeric columns to proper dtype\n",
    "for col in ['minimum', 'maximum', 'average_price']:\n",
    "    final_df[col] = pd.to_numeric(final_df[col], errors='coerce')\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 6: Save final merged CSV\n",
    "# ---------------------------------------------------------------\n",
    "output_file = os.path.join(folder, \"arrival_2022_full.csv\")\n",
    "final_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"✅ Merge complete!\")\n",
    "print(f\"💾 Saved as: {output_file}\")\n",
    "print(\"Final shape:\", final_df.shape)\n",
    "print(final_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad3dbe8e-41c9-4d77-8458-5f44e3c368cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Current working directory: D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\n",
      "✅ Found 365 CSV files to merge\n",
      "✅ Merge complete!\n",
      "💾 Saved as: D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\\arrival_2022_full.csv\n",
      "Final shape: (35088, 6)\n",
      "         Date              commodity    unit    minimum    maximum  \\\n",
      "0  2022-01-01   गोलभेडा ठूलो(नेपाली)  के.जी.  रू ११०.००  रू १२०.००   \n",
      "1  2022-01-01   गोलभेडा ठूलो(भारतीय)    केजी  रू १०१.००  रू १०१.००   \n",
      "2  2022-01-01     गोलभेडा सानो(लोकल)  के.जी.   रू ४०.००   रू ५०.००   \n",
      "3  2022-01-01     गोलभेडा सानो(टनेल)   के जी   रू ५०.००   रू ६०.००   \n",
      "4  2022-01-01   गोलभेडा सानो(भारतीय)   के जी   रू ५५.००   रू ६५.००   \n",
      "5  2022-01-01     गोलभेडा सानो(तराई)   के जी   रू ६०.००   रू ७०.००   \n",
      "6  2022-01-01               आलु रातो  के.जी.   रू ३२.००   रू ३६.००   \n",
      "7  2022-01-01       आलु रातो(भारतीय)   के जी   रू २५.००   रू ३०.००   \n",
      "8  2022-01-01               आलु सेतो  के.जी.   रू २२.००   रू २५.००   \n",
      "9  2022-01-01  प्याज सुकेको (भारतीय)  के.जी.   रू ५२.००   रू ५५.००   \n",
      "\n",
      "  average_price  \n",
      "0     रू ११५.००  \n",
      "1     रू १०१.००  \n",
      "2      रू ४५.००  \n",
      "3      रू ५५.००  \n",
      "4      रू ६०.००  \n",
      "5      रू ६५.००  \n",
      "6      रू ३३.६०  \n",
      "7      रू २७.५०  \n",
      "8      रू २३.५०  \n",
      "9      रू ५३.६०  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 1: Working directory (your notebook folder)\n",
    "# ---------------------------------------------------------------\n",
    "folder = os.getcwd()\n",
    "print(f\"📂 Current working directory: {folder}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 2: Get all CSV files (skip already merged ones)\n",
    "# ---------------------------------------------------------------\n",
    "csv_files = sorted(glob(os.path.join(folder, \"arrival_*.csv\")))\n",
    "csv_files = [f for f in csv_files if \"merge\" not in f and \"full\" not in f]\n",
    "\n",
    "print(f\"✅ Found {len(csv_files)} CSV files to merge\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 3: Define standard column names\n",
    "# ---------------------------------------------------------------\n",
    "standard_cols = ['commodity', 'unit', 'minimum', 'maximum', 'average_price']\n",
    "\n",
    "merged_data = []\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 4: Loop through all files\n",
    "# ---------------------------------------------------------------\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        # Extract date from filename\n",
    "        basename = os.path.basename(file)\n",
    "        date_str = basename.replace(\"arrival_\", \"\").replace(\".csv\", \"\")\n",
    "        parts = date_str.split(\"_\")\n",
    "        if len(parts) == 3:\n",
    "            month, day, year = parts\n",
    "            formatted_date = f\"{year}-{int(month):02d}-{int(day):02d}\"\n",
    "        else:\n",
    "            formatted_date = None\n",
    "\n",
    "        # Try reading with flexible delimiters\n",
    "        try:\n",
    "            df = pd.read_csv(file, header=None, engine='python')\n",
    "        except:\n",
    "            df = pd.read_csv(file, header=None, delimiter=';', engine='python')\n",
    "        \n",
    "        # Drop completely empty columns\n",
    "        df = df.dropna(axis=1, how='all')\n",
    "        \n",
    "        # Keep only up to 5 columns (ignore extra garbage)\n",
    "        df = df.iloc[:, :5]\n",
    "\n",
    "        # Assign standard column names\n",
    "        df.columns = standard_cols[:len(df.columns)]\n",
    "\n",
    "        # Fill missing columns if file had fewer columns\n",
    "        for col in standard_cols:\n",
    "            if col not in df.columns:\n",
    "                df[col] = None\n",
    "\n",
    "        # Add Date column\n",
    "        df['Date'] = formatted_date\n",
    "\n",
    "        # Reorder columns\n",
    "        df = df[['Date'] + standard_cols]\n",
    "\n",
    "        # Clean text columns\n",
    "        for col in ['commodity', 'unit', 'minimum', 'maximum', 'average_price']:\n",
    "            df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "        merged_data.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {file}: {e}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 5: Combine all dataframes\n",
    "# ---------------------------------------------------------------\n",
    "final_df = pd.concat(merged_data, ignore_index=True)\n",
    "final_df = final_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 6: Save merged CSV (keep as text)\n",
    "# ---------------------------------------------------------------\n",
    "output_file = os.path.join(folder, \"arrival_2022_full.csv\")\n",
    "final_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"✅ Merge complete!\")\n",
    "print(f\"💾 Saved as: {output_file}\")\n",
    "print(\"Final shape:\", final_df.shape)\n",
    "print(final_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11f9cd87-7f6c-43e8-b6d9-5d005c6d8b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>commodity</th>\n",
       "      <th>unit</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>रू ११०.००</td>\n",
       "      <td>रू १२०.००</td>\n",
       "      <td>रू ११५.००</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>गोलभेडा ठूलो(भारतीय)</td>\n",
       "      <td>केजी</td>\n",
       "      <td>रू १०१.००</td>\n",
       "      <td>रू १०१.००</td>\n",
       "      <td>रू १०१.००</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>गोलभेडा सानो(लोकल)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>रू ४०.००</td>\n",
       "      <td>रू ५०.००</td>\n",
       "      <td>रू ४५.००</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>गोलभेडा सानो(टनेल)</td>\n",
       "      <td>के जी</td>\n",
       "      <td>रू ५०.००</td>\n",
       "      <td>रू ६०.००</td>\n",
       "      <td>रू ५५.००</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>गोलभेडा सानो(भारतीय)</td>\n",
       "      <td>के जी</td>\n",
       "      <td>रू ५५.००</td>\n",
       "      <td>रू ६५.००</td>\n",
       "      <td>रू ६०.००</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date             commodity    unit    minimum    maximum  \\\n",
       "0  2022-01-01  गोलभेडा ठूलो(नेपाली)  के.जी.  रू ११०.००  रू १२०.००   \n",
       "1  2022-01-01  गोलभेडा ठूलो(भारतीय)    केजी  रू १०१.००  रू १०१.००   \n",
       "2  2022-01-01    गोलभेडा सानो(लोकल)  के.जी.   रू ४०.००   रू ५०.००   \n",
       "3  2022-01-01    गोलभेडा सानो(टनेल)   के जी   रू ५०.००   रू ६०.००   \n",
       "4  2022-01-01  गोलभेडा सानो(भारतीय)   के जी   रू ५५.००   रू ६५.००   \n",
       "\n",
       "  average_price  \n",
       "0     रू ११५.००  \n",
       "1     रू १०१.००  \n",
       "2      रू ४५.००  \n",
       "3      रू ५५.००  \n",
       "4      रू ६०.००  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('arrival_2022_full.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b75d4f2-f7ab-42b7-92da-f289937b6967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>commodity</th>\n",
       "      <th>unit</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35083</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>ताजा माछा(रहु)</td>\n",
       "      <td>के जी</td>\n",
       "      <td>रू ३२०.००</td>\n",
       "      <td>रू ३४०.००</td>\n",
       "      <td>रू ३३०.००</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35084</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>ताजा माछा(बचुवा)</td>\n",
       "      <td>के जी</td>\n",
       "      <td>रू २४०.००</td>\n",
       "      <td>रू २५०.००</td>\n",
       "      <td>रू २४५.००</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35085</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>ताजा माछा(छडी)</td>\n",
       "      <td>के जी</td>\n",
       "      <td>रू २५०.००</td>\n",
       "      <td>रू २६०.००</td>\n",
       "      <td>रू २५५.००</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35086</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>ताजा माछा(मुंगरी)</td>\n",
       "      <td>के जी</td>\n",
       "      <td>रू २६०.००</td>\n",
       "      <td>रू २८०.००</td>\n",
       "      <td>रू २७०.००</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35087</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>रुख टमाटर</td>\n",
       "      <td>केजी</td>\n",
       "      <td>रू ७०.००</td>\n",
       "      <td>रू ८०.००</td>\n",
       "      <td>रू ७५.००</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date          commodity   unit    minimum    maximum  \\\n",
       "35083  2022-12-31     ताजा माछा(रहु)  के जी  रू ३२०.००  रू ३४०.००   \n",
       "35084  2022-12-31   ताजा माछा(बचुवा)  के जी  रू २४०.००  रू २५०.००   \n",
       "35085  2022-12-31     ताजा माछा(छडी)  के जी  रू २५०.००  रू २६०.००   \n",
       "35086  2022-12-31  ताजा माछा(मुंगरी)  के जी  रू २६०.००  रू २८०.००   \n",
       "35087  2022-12-31          रुख टमाटर   केजी   रू ७०.००   रू ८०.००   \n",
       "\n",
       "      average_price  \n",
       "35083     रू ३३०.००  \n",
       "35084     रू २४५.००  \n",
       "35085     रू २५५.००  \n",
       "35086     रू २७०.००  \n",
       "35087      रू ७५.००  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c465fc5-9d95-4739-b4ab-2bd7cc4ad02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tomato_big = df[df['commodity']=='गोलभेडा ठूलो(नेपाली)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d984c909-3a73-4f94-84c6-9ea7cbfd0b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>commodity</th>\n",
       "      <th>unit</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>रू ११०.००</td>\n",
       "      <td>रू १२०.००</td>\n",
       "      <td>रू ११५.००</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>रू ११०.००</td>\n",
       "      <td>रू १२०.००</td>\n",
       "      <td>रू ११५.००</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>रू ९०.००</td>\n",
       "      <td>रू १००.००</td>\n",
       "      <td>रू ९५.००</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>रू ९०.००</td>\n",
       "      <td>रू १००.००</td>\n",
       "      <td>रू ९६.६७</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>रू ८०.००</td>\n",
       "      <td>रू ९०.००</td>\n",
       "      <td>रू ८६.६७</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34521</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>रू ४५.००</td>\n",
       "      <td>रू ५५.००</td>\n",
       "      <td>रू ५०.००</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34633</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>रू ५०.००</td>\n",
       "      <td>रू ६०.००</td>\n",
       "      <td>रू ५५.००</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34747</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>रू ४०.००</td>\n",
       "      <td>रू ५०.००</td>\n",
       "      <td>रू ४५.००</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34860</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>रू ४०.००</td>\n",
       "      <td>रू ५०.००</td>\n",
       "      <td>रू ४५.००</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34974</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>रू ४०.००</td>\n",
       "      <td>रू ५०.००</td>\n",
       "      <td>रू ४५.००</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date             commodity    unit    minimum    maximum  \\\n",
       "0      2022-01-01  गोलभेडा ठूलो(नेपाली)  के.जी.  रू ११०.००  रू १२०.००   \n",
       "109    2022-01-02  गोलभेडा ठूलो(नेपाली)  के.जी.  रू ११०.००  रू १२०.००   \n",
       "216    2022-01-03  गोलभेडा ठूलो(नेपाली)  के.जी.   रू ९०.००  रू १००.००   \n",
       "323    2022-01-04  गोलभेडा ठूलो(नेपाली)  के.जी.   रू ९०.००  रू १००.००   \n",
       "430    2022-01-05  गोलभेडा ठूलो(नेपाली)  के.जी.   रू ८०.००   रू ९०.००   \n",
       "...           ...                   ...     ...        ...        ...   \n",
       "34521  2022-12-27  गोलभेडा ठूलो(नेपाली)  के.जी.   रू ४५.००   रू ५५.००   \n",
       "34633  2022-12-28  गोलभेडा ठूलो(नेपाली)  के.जी.   रू ५०.००   रू ६०.००   \n",
       "34747  2022-12-29  गोलभेडा ठूलो(नेपाली)  के.जी.   रू ४०.००   रू ५०.००   \n",
       "34860  2022-12-30  गोलभेडा ठूलो(नेपाली)  के.जी.   रू ४०.००   रू ५०.००   \n",
       "34974  2022-12-31  गोलभेडा ठूलो(नेपाली)  के.जी.   रू ४०.००   रू ५०.००   \n",
       "\n",
       "      average_price  \n",
       "0         रू ११५.००  \n",
       "109       रू ११५.००  \n",
       "216        रू ९५.००  \n",
       "323        रू ९६.६७  \n",
       "430        रू ८६.६७  \n",
       "...             ...  \n",
       "34521      रू ५०.००  \n",
       "34633      रू ५५.००  \n",
       "34747      रू ४५.००  \n",
       "34860      रू ४५.००  \n",
       "34974      रू ४५.००  \n",
       "\n",
       "[303 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tomato_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43bb759b-7540-425a-9085-b65e3cc99db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mapping Nepali to English digits\n",
    "nep_to_eng = str.maketrans('०१२३४५६७८९', '0123456789')\n",
    "\n",
    "# Apply translation to all string columns\n",
    "# df1 = df1.applymap(lambda x: x.translate(nep_to_eng) if isinstance(x, str) else x)\n",
    "df_tomato_big = df_tomato_big.apply(lambda col: col.map(lambda x: x.translate(nep_to_eng) if isinstance(x, str) else x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87b07c2c-1459-4fc6-b80d-63a8ee51dc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>commodity</th>\n",
       "      <th>unit</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>रू 110.00</td>\n",
       "      <td>रू 120.00</td>\n",
       "      <td>रू 115.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>रू 110.00</td>\n",
       "      <td>रू 120.00</td>\n",
       "      <td>रू 115.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>रू 90.00</td>\n",
       "      <td>रू 100.00</td>\n",
       "      <td>रू 95.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>रू 90.00</td>\n",
       "      <td>रू 100.00</td>\n",
       "      <td>रू 96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>रू 80.00</td>\n",
       "      <td>रू 90.00</td>\n",
       "      <td>रू 86.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date             commodity    unit    minimum    maximum  \\\n",
       "0    2022-01-01  गोलभेडा ठूलो(नेपाली)  के.जी.  रू 110.00  रू 120.00   \n",
       "109  2022-01-02  गोलभेडा ठूलो(नेपाली)  के.जी.  रू 110.00  रू 120.00   \n",
       "216  2022-01-03  गोलभेडा ठूलो(नेपाली)  के.जी.   रू 90.00  रू 100.00   \n",
       "323  2022-01-04  गोलभेडा ठूलो(नेपाली)  के.जी.   रू 90.00  रू 100.00   \n",
       "430  2022-01-05  गोलभेडा ठूलो(नेपाली)  के.जी.   रू 80.00   रू 90.00   \n",
       "\n",
       "    average_price  \n",
       "0       रू 115.00  \n",
       "109     रू 115.00  \n",
       "216      रू 95.00  \n",
       "323      रू 96.67  \n",
       "430      रू 86.67  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tomato_big.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aad366fe-4a0a-49cc-990b-8d6b9f932847",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tomato_big['minimum']= df_tomato_big['minimum'].str.split(' ').str[1]\n",
    "df_tomato_big['maximum']= df_tomato_big['maximum'].str.split(' ').str[1]\n",
    "df_tomato_big['average_price']= df_tomato_big['average_price'].str.split(' ').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9606c40-30e7-404f-8ec0-d4b7ca03b229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>commodity</th>\n",
       "      <th>unit</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>110.00</td>\n",
       "      <td>120.00</td>\n",
       "      <td>115.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>110.00</td>\n",
       "      <td>120.00</td>\n",
       "      <td>115.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>90.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>95.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>90.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>80.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>86.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34521</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>45.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34633</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>50.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>55.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34747</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>40.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>45.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34860</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>40.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>45.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34974</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>गोलभेडा ठूलो(नेपाली)</td>\n",
       "      <td>के.जी.</td>\n",
       "      <td>40.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>45.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date             commodity    unit minimum maximum average_price\n",
       "0      2022-01-01  गोलभेडा ठूलो(नेपाली)  के.जी.  110.00  120.00        115.00\n",
       "109    2022-01-02  गोलभेडा ठूलो(नेपाली)  के.जी.  110.00  120.00        115.00\n",
       "216    2022-01-03  गोलभेडा ठूलो(नेपाली)  के.जी.   90.00  100.00         95.00\n",
       "323    2022-01-04  गोलभेडा ठूलो(नेपाली)  के.जी.   90.00  100.00         96.67\n",
       "430    2022-01-05  गोलभेडा ठूलो(नेपाली)  के.जी.   80.00   90.00         86.67\n",
       "...           ...                   ...     ...     ...     ...           ...\n",
       "34521  2022-12-27  गोलभेडा ठूलो(नेपाली)  के.जी.   45.00   55.00         50.00\n",
       "34633  2022-12-28  गोलभेडा ठूलो(नेपाली)  के.जी.   50.00   60.00         55.00\n",
       "34747  2022-12-29  गोलभेडा ठूलो(नेपाली)  के.जी.   40.00   50.00         45.00\n",
       "34860  2022-12-30  गोलभेडा ठूलो(नेपाली)  के.जी.   40.00   50.00         45.00\n",
       "34974  2022-12-31  गोलभेडा ठूलो(नेपाली)  के.जी.   40.00   50.00         45.00\n",
       "\n",
       "[303 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tomato_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89421e26-b8e5-4735-a57f-e1adcd861173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myConda)",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
