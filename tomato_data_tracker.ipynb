{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "565637c8-68e5-45a4-b742-848ab5570cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 01/01/2022\n",
      "Saved data to arrival_01_01_2022.csv\n",
      "Processing 01/02/2022\n",
      "Saved data to arrival_01_02_2022.csv\n",
      "Processing 01/03/2022\n",
      "Saved data to arrival_01_03_2022.csv\n",
      "Processing 01/04/2022\n",
      "Saved data to arrival_01_04_2022.csv\n",
      "Processing 01/05/2022\n",
      "Saved data to arrival_01_05_2022.csv\n",
      "Processing 01/06/2022\n",
      "Saved data to arrival_01_06_2022.csv\n",
      "Processing 01/07/2022\n",
      "Saved data to arrival_01_07_2022.csv\n",
      "Processing 01/08/2022\n",
      "Saved data to arrival_01_08_2022.csv\n",
      "Processing 01/09/2022\n",
      "Saved data to arrival_01_09_2022.csv\n",
      "Processing 01/10/2022\n",
      "Saved data to arrival_01_10_2022.csv\n",
      "Processing 01/11/2022\n",
      "Saved data to arrival_01_11_2022.csv\n",
      "Processing 01/12/2022\n",
      "Saved data to arrival_01_12_2022.csv\n",
      "Processing 01/13/2022\n",
      "Saved data to arrival_01_13_2022.csv\n",
      "Processing 01/14/2022\n",
      "Saved data to arrival_01_14_2022.csv\n",
      "Processing 01/15/2022\n",
      "Saved data to arrival_01_15_2022.csv\n",
      "Processing 01/16/2022\n",
      "Saved data to arrival_01_16_2022.csv\n",
      "Processing 01/17/2022\n",
      "Saved data to arrival_01_17_2022.csv\n",
      "Processing 01/18/2022\n",
      "Saved data to arrival_01_18_2022.csv\n",
      "Processing 01/19/2022\n",
      "Saved data to arrival_01_19_2022.csv\n",
      "Processing 01/20/2022\n",
      "Saved data to arrival_01_20_2022.csv\n",
      "Processing 01/21/2022\n",
      "Saved data to arrival_01_21_2022.csv\n",
      "Processing 01/22/2022\n",
      "Saved data to arrival_01_22_2022.csv\n",
      "Processing 01/23/2022\n",
      "Saved data to arrival_01_23_2022.csv\n",
      "Processing 01/24/2022\n",
      "Saved data to arrival_01_24_2022.csv\n",
      "Processing 01/25/2022\n",
      "Saved data to arrival_01_25_2022.csv\n",
      "Processing 01/26/2022\n",
      "Saved data to arrival_01_26_2022.csv\n",
      "Processing 01/27/2022\n",
      "Saved data to arrival_01_27_2022.csv\n",
      "Processing 01/28/2022\n",
      "Saved data to arrival_01_28_2022.csv\n",
      "Processing 01/29/2022\n",
      "Saved data to arrival_01_29_2022.csv\n",
      "Processing 01/30/2022\n",
      "Saved data to arrival_01_30_2022.csv\n",
      "Processing 01/31/2022\n",
      "Saved data to arrival_01_31_2022.csv\n",
      "Processing 02/01/2022\n",
      "Saved data to arrival_02_01_2022.csv\n",
      "Processing 02/02/2022\n",
      "Saved data to arrival_02_02_2022.csv\n",
      "Processing 02/03/2022\n",
      "Saved data to arrival_02_03_2022.csv\n",
      "Processing 02/04/2022\n",
      "Saved data to arrival_02_04_2022.csv\n",
      "Processing 02/05/2022\n",
      "Saved data to arrival_02_05_2022.csv\n",
      "Processing 02/06/2022\n",
      "Saved data to arrival_02_06_2022.csv\n",
      "Processing 02/07/2022\n",
      "Saved data to arrival_02_07_2022.csv\n",
      "Processing 02/08/2022\n",
      "Saved data to arrival_02_08_2022.csv\n",
      "Processing 02/09/2022\n",
      "Saved data to arrival_02_09_2022.csv\n",
      "Processing 02/10/2022\n",
      "Saved data to arrival_02_10_2022.csv\n",
      "Processing 02/11/2022\n",
      "Saved data to arrival_02_11_2022.csv\n",
      "Processing 02/12/2022\n",
      "Saved data to arrival_02_12_2022.csv\n",
      "Processing 02/13/2022\n",
      "Saved data to arrival_02_13_2022.csv\n",
      "Processing 02/14/2022\n",
      "Saved data to arrival_02_14_2022.csv\n",
      "Processing 02/15/2022\n",
      "Saved data to arrival_02_15_2022.csv\n",
      "Processing 02/16/2022\n",
      "Saved data to arrival_02_16_2022.csv\n",
      "Processing 02/17/2022\n",
      "Saved data to arrival_02_17_2022.csv\n",
      "Processing 02/18/2022\n",
      "Saved data to arrival_02_18_2022.csv\n",
      "Processing 02/19/2022\n",
      "Saved data to arrival_02_19_2022.csv\n",
      "Processing 02/20/2022\n",
      "Saved data to arrival_02_20_2022.csv\n",
      "Processing 02/21/2022\n",
      "Saved data to arrival_02_21_2022.csv\n",
      "Processing 02/22/2022\n",
      "Saved data to arrival_02_22_2022.csv\n",
      "Processing 02/23/2022\n",
      "Saved data to arrival_02_23_2022.csv\n",
      "Processing 02/24/2022\n",
      "Saved data to arrival_02_24_2022.csv\n",
      "Processing 02/25/2022\n",
      "Saved data to arrival_02_25_2022.csv\n",
      "Processing 02/26/2022\n",
      "Saved data to arrival_02_26_2022.csv\n",
      "Processing 02/27/2022\n",
      "Saved data to arrival_02_27_2022.csv\n",
      "Processing 02/28/2022\n",
      "Saved data to arrival_02_28_2022.csv\n",
      "Processing 03/01/2022\n",
      "Saved data to arrival_03_01_2022.csv\n",
      "Processing 03/02/2022\n",
      "Saved data to arrival_03_02_2022.csv\n",
      "Processing 03/03/2022\n",
      "Saved data to arrival_03_03_2022.csv\n",
      "Processing 03/04/2022\n",
      "Saved data to arrival_03_04_2022.csv\n",
      "Processing 03/05/2022\n",
      "Saved data to arrival_03_05_2022.csv\n",
      "Processing 03/06/2022\n",
      "Saved data to arrival_03_06_2022.csv\n",
      "Processing 03/07/2022\n",
      "Saved data to arrival_03_07_2022.csv\n",
      "Processing 03/08/2022\n",
      "Saved data to arrival_03_08_2022.csv\n",
      "Processing 03/09/2022\n",
      "Saved data to arrival_03_09_2022.csv\n",
      "Processing 03/10/2022\n",
      "Saved data to arrival_03_10_2022.csv\n",
      "Processing 03/11/2022\n",
      "Saved data to arrival_03_11_2022.csv\n",
      "Processing 03/12/2022\n",
      "Saved data to arrival_03_12_2022.csv\n",
      "Processing 03/13/2022\n",
      "Saved data to arrival_03_13_2022.csv\n",
      "Processing 03/14/2022\n",
      "Saved data to arrival_03_14_2022.csv\n",
      "Processing 03/15/2022\n",
      "Saved data to arrival_03_15_2022.csv\n",
      "Processing 03/16/2022\n",
      "Saved data to arrival_03_16_2022.csv\n",
      "Processing 03/17/2022\n",
      "Saved data to arrival_03_17_2022.csv\n",
      "Processing 03/18/2022\n",
      "Saved data to arrival_03_18_2022.csv\n",
      "Processing 03/19/2022\n",
      "Saved data to arrival_03_19_2022.csv\n",
      "Processing 03/20/2022\n",
      "Saved data to arrival_03_20_2022.csv\n",
      "Processing 03/21/2022\n",
      "Saved data to arrival_03_21_2022.csv\n",
      "Processing 03/22/2022\n",
      "Saved data to arrival_03_22_2022.csv\n",
      "Processing 03/23/2022\n",
      "Saved data to arrival_03_23_2022.csv\n",
      "Processing 03/24/2022\n",
      "Saved data to arrival_03_24_2022.csv\n",
      "Processing 03/25/2022\n",
      "Saved data to arrival_03_25_2022.csv\n",
      "Processing 03/26/2022\n",
      "Saved data to arrival_03_26_2022.csv\n",
      "Processing 03/27/2022\n",
      "Saved data to arrival_03_27_2022.csv\n",
      "Processing 03/28/2022\n",
      "Saved data to arrival_03_28_2022.csv\n",
      "Processing 03/29/2022\n",
      "Saved data to arrival_03_29_2022.csv\n",
      "Processing 03/30/2022\n",
      "Saved data to arrival_03_30_2022.csv\n",
      "Processing 03/31/2022\n",
      "Saved data to arrival_03_31_2022.csv\n",
      "Processing 04/01/2022\n",
      "Saved data to arrival_04_01_2022.csv\n",
      "Processing 04/02/2022\n",
      "Saved data to arrival_04_02_2022.csv\n",
      "Processing 04/03/2022\n",
      "Saved data to arrival_04_03_2022.csv\n",
      "Processing 04/04/2022\n",
      "Saved data to arrival_04_04_2022.csv\n",
      "Processing 04/05/2022\n",
      "Saved data to arrival_04_05_2022.csv\n",
      "Processing 04/06/2022\n",
      "Saved data to arrival_04_06_2022.csv\n",
      "Processing 04/07/2022\n",
      "Saved data to arrival_04_07_2022.csv\n",
      "Processing 04/08/2022\n",
      "Saved data to arrival_04_08_2022.csv\n",
      "Processing 04/09/2022\n",
      "Saved data to arrival_04_09_2022.csv\n",
      "Processing 04/10/2022\n",
      "Saved data to arrival_04_10_2022.csv\n",
      "Processing 04/11/2022\n",
      "Saved data to arrival_04_11_2022.csv\n",
      "Processing 04/12/2022\n",
      "Saved data to arrival_04_12_2022.csv\n",
      "Processing 04/13/2022\n",
      "Saved data to arrival_04_13_2022.csv\n",
      "Processing 04/14/2022\n",
      "Saved data to arrival_04_14_2022.csv\n",
      "Processing 04/15/2022\n",
      "Saved data to arrival_04_15_2022.csv\n",
      "Processing 04/16/2022\n",
      "Saved data to arrival_04_16_2022.csv\n",
      "Processing 04/17/2022\n",
      "Saved data to arrival_04_17_2022.csv\n",
      "Processing 04/18/2022\n",
      "Saved data to arrival_04_18_2022.csv\n",
      "Processing 04/19/2022\n",
      "Saved data to arrival_04_19_2022.csv\n",
      "Processing 04/20/2022\n",
      "Saved data to arrival_04_20_2022.csv\n",
      "Processing 04/21/2022\n",
      "Saved data to arrival_04_21_2022.csv\n",
      "Processing 04/22/2022\n",
      "Saved data to arrival_04_22_2022.csv\n",
      "Processing 04/23/2022\n",
      "Saved data to arrival_04_23_2022.csv\n",
      "Processing 04/24/2022\n",
      "Saved data to arrival_04_24_2022.csv\n",
      "Processing 04/25/2022\n",
      "Saved data to arrival_04_25_2022.csv\n",
      "Processing 04/26/2022\n",
      "Saved data to arrival_04_26_2022.csv\n",
      "Processing 04/27/2022\n",
      "Saved data to arrival_04_27_2022.csv\n",
      "Processing 04/28/2022\n",
      "Saved data to arrival_04_28_2022.csv\n",
      "Processing 04/29/2022\n",
      "Saved data to arrival_04_29_2022.csv\n",
      "Processing 04/30/2022\n",
      "Saved data to arrival_04_30_2022.csv\n",
      "Processing 05/01/2022\n",
      "Saved data to arrival_05_01_2022.csv\n",
      "Processing 05/02/2022\n",
      "Saved data to arrival_05_02_2022.csv\n",
      "Processing 05/03/2022\n",
      "Saved data to arrival_05_03_2022.csv\n",
      "Processing 05/04/2022\n",
      "Saved data to arrival_05_04_2022.csv\n",
      "Processing 05/05/2022\n",
      "Saved data to arrival_05_05_2022.csv\n",
      "Processing 05/06/2022\n",
      "Saved data to arrival_05_06_2022.csv\n",
      "Processing 05/07/2022\n",
      "Saved data to arrival_05_07_2022.csv\n",
      "Processing 05/08/2022\n",
      "Saved data to arrival_05_08_2022.csv\n",
      "Processing 05/09/2022\n",
      "Saved data to arrival_05_09_2022.csv\n",
      "Processing 05/10/2022\n",
      "Saved data to arrival_05_10_2022.csv\n",
      "Processing 05/11/2022\n",
      "Saved data to arrival_05_11_2022.csv\n",
      "Processing 05/12/2022\n",
      "Saved data to arrival_05_12_2022.csv\n",
      "Processing 05/13/2022\n",
      "Saved data to arrival_05_13_2022.csv\n",
      "Processing 05/14/2022\n",
      "Saved data to arrival_05_14_2022.csv\n",
      "Processing 05/15/2022\n",
      "Saved data to arrival_05_15_2022.csv\n",
      "Processing 05/16/2022\n",
      "Saved data to arrival_05_16_2022.csv\n",
      "Processing 05/17/2022\n",
      "Saved data to arrival_05_17_2022.csv\n",
      "Processing 05/18/2022\n",
      "Saved data to arrival_05_18_2022.csv\n",
      "Processing 05/19/2022\n",
      "Saved data to arrival_05_19_2022.csv\n",
      "Processing 05/20/2022\n",
      "Saved data to arrival_05_20_2022.csv\n",
      "Processing 05/21/2022\n",
      "Saved data to arrival_05_21_2022.csv\n",
      "Processing 05/22/2022\n",
      "Saved data to arrival_05_22_2022.csv\n",
      "Processing 05/23/2022\n",
      "Saved data to arrival_05_23_2022.csv\n",
      "Processing 05/24/2022\n",
      "Saved data to arrival_05_24_2022.csv\n",
      "Processing 05/25/2022\n",
      "Saved data to arrival_05_25_2022.csv\n",
      "Processing 05/26/2022\n",
      "Saved data to arrival_05_26_2022.csv\n",
      "Processing 05/27/2022\n",
      "Saved data to arrival_05_27_2022.csv\n",
      "Processing 05/28/2022\n",
      "Saved data to arrival_05_28_2022.csv\n",
      "Processing 05/29/2022\n",
      "Saved data to arrival_05_29_2022.csv\n",
      "Processing 05/30/2022\n",
      "Saved data to arrival_05_30_2022.csv\n",
      "Processing 05/31/2022\n",
      "Saved data to arrival_05_31_2022.csv\n",
      "Processing 06/01/2022\n",
      "Saved data to arrival_06_01_2022.csv\n",
      "Processing 06/02/2022\n",
      "Saved data to arrival_06_02_2022.csv\n",
      "Processing 06/03/2022\n",
      "Saved data to arrival_06_03_2022.csv\n",
      "Processing 06/04/2022\n",
      "Saved data to arrival_06_04_2022.csv\n",
      "Processing 06/05/2022\n",
      "Saved data to arrival_06_05_2022.csv\n",
      "Processing 06/06/2022\n",
      "Saved data to arrival_06_06_2022.csv\n",
      "Processing 06/07/2022\n",
      "Saved data to arrival_06_07_2022.csv\n",
      "Processing 06/08/2022\n",
      "Saved data to arrival_06_08_2022.csv\n",
      "Processing 06/09/2022\n",
      "Saved data to arrival_06_09_2022.csv\n",
      "Processing 06/10/2022\n",
      "Saved data to arrival_06_10_2022.csv\n",
      "Processing 06/11/2022\n",
      "Saved data to arrival_06_11_2022.csv\n",
      "Processing 06/12/2022\n",
      "Saved data to arrival_06_12_2022.csv\n",
      "Processing 06/13/2022\n",
      "Saved data to arrival_06_13_2022.csv\n",
      "Processing 06/14/2022\n",
      "Saved data to arrival_06_14_2022.csv\n",
      "Processing 06/15/2022\n",
      "Saved data to arrival_06_15_2022.csv\n",
      "Processing 06/16/2022\n",
      "Saved data to arrival_06_16_2022.csv\n",
      "Processing 06/17/2022\n",
      "Saved data to arrival_06_17_2022.csv\n",
      "Processing 06/18/2022\n",
      "Saved data to arrival_06_18_2022.csv\n",
      "Processing 06/19/2022\n",
      "Saved data to arrival_06_19_2022.csv\n",
      "Processing 06/20/2022\n",
      "Saved data to arrival_06_20_2022.csv\n",
      "Processing 06/21/2022\n",
      "Saved data to arrival_06_21_2022.csv\n",
      "Processing 06/22/2022\n",
      "Saved data to arrival_06_22_2022.csv\n",
      "Processing 06/23/2022\n",
      "Saved data to arrival_06_23_2022.csv\n",
      "Processing 06/24/2022\n",
      "Saved data to arrival_06_24_2022.csv\n",
      "Processing 06/25/2022\n",
      "Saved data to arrival_06_25_2022.csv\n",
      "Processing 06/26/2022\n",
      "Saved data to arrival_06_26_2022.csv\n",
      "Processing 06/27/2022\n",
      "Saved data to arrival_06_27_2022.csv\n",
      "Processing 06/28/2022\n",
      "Saved data to arrival_06_28_2022.csv\n",
      "Processing 06/29/2022\n",
      "Saved data to arrival_06_29_2022.csv\n",
      "Processing 06/30/2022\n",
      "Saved data to arrival_06_30_2022.csv\n",
      "Processing 07/01/2022\n",
      "Saved data to arrival_07_01_2022.csv\n",
      "Processing 07/02/2022\n",
      "Saved data to arrival_07_02_2022.csv\n",
      "Processing 07/03/2022\n",
      "Saved data to arrival_07_03_2022.csv\n",
      "Processing 07/04/2022\n",
      "Saved data to arrival_07_04_2022.csv\n",
      "Processing 07/05/2022\n",
      "Saved data to arrival_07_05_2022.csv\n",
      "Processing 07/06/2022\n",
      "Saved data to arrival_07_06_2022.csv\n",
      "Processing 07/07/2022\n",
      "Saved data to arrival_07_07_2022.csv\n",
      "Processing 07/08/2022\n",
      "Saved data to arrival_07_08_2022.csv\n",
      "Processing 07/09/2022\n",
      "Saved data to arrival_07_09_2022.csv\n",
      "Processing 07/10/2022\n",
      "Saved data to arrival_07_10_2022.csv\n",
      "Processing 07/11/2022\n",
      "Saved data to arrival_07_11_2022.csv\n",
      "Processing 07/12/2022\n",
      "Saved data to arrival_07_12_2022.csv\n",
      "Processing 07/13/2022\n",
      "Saved data to arrival_07_13_2022.csv\n",
      "Processing 07/14/2022\n",
      "Saved data to arrival_07_14_2022.csv\n",
      "Processing 07/15/2022\n",
      "Saved data to arrival_07_15_2022.csv\n",
      "Processing 07/16/2022\n",
      "Saved data to arrival_07_16_2022.csv\n",
      "Processing 07/17/2022\n",
      "Saved data to arrival_07_17_2022.csv\n",
      "Processing 07/18/2022\n",
      "Saved data to arrival_07_18_2022.csv\n",
      "Processing 07/19/2022\n",
      "Saved data to arrival_07_19_2022.csv\n",
      "Processing 07/20/2022\n",
      "Saved data to arrival_07_20_2022.csv\n",
      "Processing 07/21/2022\n",
      "Saved data to arrival_07_21_2022.csv\n",
      "Processing 07/22/2022\n",
      "Saved data to arrival_07_22_2022.csv\n",
      "Processing 07/23/2022\n",
      "Saved data to arrival_07_23_2022.csv\n",
      "Processing 07/24/2022\n",
      "Saved data to arrival_07_24_2022.csv\n",
      "Processing 07/25/2022\n",
      "Saved data to arrival_07_25_2022.csv\n",
      "Processing 07/26/2022\n",
      "Saved data to arrival_07_26_2022.csv\n",
      "Processing 07/27/2022\n",
      "Saved data to arrival_07_27_2022.csv\n",
      "Processing 07/28/2022\n",
      "Saved data to arrival_07_28_2022.csv\n",
      "Processing 07/29/2022\n",
      "Saved data to arrival_07_29_2022.csv\n",
      "Processing 07/30/2022\n",
      "Saved data to arrival_07_30_2022.csv\n",
      "Processing 07/31/2022\n",
      "Saved data to arrival_07_31_2022.csv\n",
      "Processing 08/01/2022\n",
      "Saved data to arrival_08_01_2022.csv\n",
      "Processing 08/02/2022\n",
      "Saved data to arrival_08_02_2022.csv\n",
      "Processing 08/03/2022\n",
      "Saved data to arrival_08_03_2022.csv\n",
      "Processing 08/04/2022\n",
      "Saved data to arrival_08_04_2022.csv\n",
      "Processing 08/05/2022\n",
      "Saved data to arrival_08_05_2022.csv\n",
      "Processing 08/06/2022\n",
      "Saved data to arrival_08_06_2022.csv\n",
      "Processing 08/07/2022\n",
      "Saved data to arrival_08_07_2022.csv\n",
      "Processing 08/08/2022\n",
      "Saved data to arrival_08_08_2022.csv\n",
      "Processing 08/09/2022\n",
      "Saved data to arrival_08_09_2022.csv\n",
      "Processing 08/10/2022\n",
      "Saved data to arrival_08_10_2022.csv\n",
      "Processing 08/11/2022\n",
      "Saved data to arrival_08_11_2022.csv\n",
      "Processing 08/12/2022\n",
      "Saved data to arrival_08_12_2022.csv\n",
      "Processing 08/13/2022\n",
      "Saved data to arrival_08_13_2022.csv\n",
      "Processing 08/14/2022\n",
      "Saved data to arrival_08_14_2022.csv\n",
      "Processing 08/15/2022\n",
      "Saved data to arrival_08_15_2022.csv\n",
      "Processing 08/16/2022\n",
      "Saved data to arrival_08_16_2022.csv\n",
      "Processing 08/17/2022\n",
      "Saved data to arrival_08_17_2022.csv\n",
      "Processing 08/18/2022\n",
      "Saved data to arrival_08_18_2022.csv\n",
      "Processing 08/19/2022\n",
      "Saved data to arrival_08_19_2022.csv\n",
      "Processing 08/20/2022\n",
      "Saved data to arrival_08_20_2022.csv\n",
      "Processing 08/21/2022\n",
      "Saved data to arrival_08_21_2022.csv\n",
      "Processing 08/22/2022\n",
      "Saved data to arrival_08_22_2022.csv\n",
      "Processing 08/23/2022\n",
      "Saved data to arrival_08_23_2022.csv\n",
      "Processing 08/24/2022\n",
      "Saved data to arrival_08_24_2022.csv\n",
      "Processing 08/25/2022\n",
      "Saved data to arrival_08_25_2022.csv\n",
      "Processing 08/26/2022\n",
      "Saved data to arrival_08_26_2022.csv\n",
      "Processing 08/27/2022\n",
      "Saved data to arrival_08_27_2022.csv\n",
      "Processing 08/28/2022\n",
      "Saved data to arrival_08_28_2022.csv\n",
      "Processing 08/29/2022\n",
      "Saved data to arrival_08_29_2022.csv\n",
      "Processing 08/30/2022\n",
      "Saved data to arrival_08_30_2022.csv\n",
      "Processing 08/31/2022\n",
      "Saved data to arrival_08_31_2022.csv\n",
      "Processing 09/01/2022\n",
      "Saved data to arrival_09_01_2022.csv\n",
      "Processing 09/02/2022\n",
      "Saved data to arrival_09_02_2022.csv\n",
      "Processing 09/03/2022\n",
      "Saved data to arrival_09_03_2022.csv\n",
      "Processing 09/04/2022\n",
      "Saved data to arrival_09_04_2022.csv\n",
      "Processing 09/05/2022\n",
      "Saved data to arrival_09_05_2022.csv\n",
      "Processing 09/06/2022\n",
      "Saved data to arrival_09_06_2022.csv\n",
      "Processing 09/07/2022\n",
      "Saved data to arrival_09_07_2022.csv\n",
      "Processing 09/08/2022\n",
      "Saved data to arrival_09_08_2022.csv\n",
      "Processing 09/09/2022\n",
      "Saved data to arrival_09_09_2022.csv\n",
      "Processing 09/10/2022\n",
      "Saved data to arrival_09_10_2022.csv\n",
      "Processing 09/11/2022\n",
      "Saved data to arrival_09_11_2022.csv\n",
      "Processing 09/12/2022\n",
      "Saved data to arrival_09_12_2022.csv\n",
      "Processing 09/13/2022\n",
      "Saved data to arrival_09_13_2022.csv\n",
      "Processing 09/14/2022\n",
      "Saved data to arrival_09_14_2022.csv\n",
      "Processing 09/15/2022\n",
      "Saved data to arrival_09_15_2022.csv\n",
      "Processing 09/16/2022\n",
      "Saved data to arrival_09_16_2022.csv\n",
      "Processing 09/17/2022\n",
      "Saved data to arrival_09_17_2022.csv\n",
      "Processing 09/18/2022\n",
      "Saved data to arrival_09_18_2022.csv\n",
      "Processing 09/19/2022\n",
      "Saved data to arrival_09_19_2022.csv\n",
      "Processing 09/20/2022\n",
      "Saved data to arrival_09_20_2022.csv\n",
      "Processing 09/21/2022\n",
      "Saved data to arrival_09_21_2022.csv\n",
      "Processing 09/22/2022\n",
      "Saved data to arrival_09_22_2022.csv\n",
      "Processing 09/23/2022\n",
      "Saved data to arrival_09_23_2022.csv\n",
      "Processing 09/24/2022\n",
      "Saved data to arrival_09_24_2022.csv\n",
      "Processing 09/25/2022\n",
      "Saved data to arrival_09_25_2022.csv\n",
      "Processing 09/26/2022\n",
      "Saved data to arrival_09_26_2022.csv\n",
      "Processing 09/27/2022\n",
      "Saved data to arrival_09_27_2022.csv\n",
      "Processing 09/28/2022\n",
      "Saved data to arrival_09_28_2022.csv\n",
      "Processing 09/29/2022\n",
      "Saved data to arrival_09_29_2022.csv\n",
      "Processing 09/30/2022\n",
      "Saved data to arrival_09_30_2022.csv\n",
      "Processing 10/01/2022\n",
      "Saved data to arrival_10_01_2022.csv\n",
      "Processing 10/02/2022\n",
      "Saved data to arrival_10_02_2022.csv\n",
      "Processing 10/03/2022\n",
      "Saved data to arrival_10_03_2022.csv\n",
      "Processing 10/04/2022\n",
      "Saved data to arrival_10_04_2022.csv\n",
      "Processing 10/05/2022\n",
      "Saved data to arrival_10_05_2022.csv\n",
      "Processing 10/06/2022\n",
      "Saved data to arrival_10_06_2022.csv\n",
      "Processing 10/07/2022\n",
      "Saved data to arrival_10_07_2022.csv\n",
      "Processing 10/08/2022\n",
      "Saved data to arrival_10_08_2022.csv\n",
      "Processing 10/09/2022\n",
      "Saved data to arrival_10_09_2022.csv\n",
      "Processing 10/10/2022\n",
      "Saved data to arrival_10_10_2022.csv\n",
      "Processing 10/11/2022\n",
      "Saved data to arrival_10_11_2022.csv\n",
      "Processing 10/12/2022\n",
      "Saved data to arrival_10_12_2022.csv\n",
      "Processing 10/13/2022\n",
      "Saved data to arrival_10_13_2022.csv\n",
      "Processing 10/14/2022\n",
      "Saved data to arrival_10_14_2022.csv\n",
      "Processing 10/15/2022\n",
      "Saved data to arrival_10_15_2022.csv\n",
      "Processing 10/16/2022\n",
      "Saved data to arrival_10_16_2022.csv\n",
      "Processing 10/17/2022\n",
      "Saved data to arrival_10_17_2022.csv\n",
      "Processing 10/18/2022\n",
      "Saved data to arrival_10_18_2022.csv\n",
      "Processing 10/19/2022\n",
      "Saved data to arrival_10_19_2022.csv\n",
      "Processing 10/20/2022\n",
      "Saved data to arrival_10_20_2022.csv\n",
      "Processing 10/21/2022\n",
      "Saved data to arrival_10_21_2022.csv\n",
      "Processing 10/22/2022\n",
      "Saved data to arrival_10_22_2022.csv\n",
      "Processing 10/23/2022\n",
      "Saved data to arrival_10_23_2022.csv\n",
      "Processing 10/24/2022\n",
      "Saved data to arrival_10_24_2022.csv\n",
      "Processing 10/25/2022\n",
      "Saved data to arrival_10_25_2022.csv\n",
      "Processing 10/26/2022\n",
      "Saved data to arrival_10_26_2022.csv\n",
      "Processing 10/27/2022\n",
      "Saved data to arrival_10_27_2022.csv\n",
      "Processing 10/28/2022\n",
      "Saved data to arrival_10_28_2022.csv\n",
      "Processing 10/29/2022\n",
      "Saved data to arrival_10_29_2022.csv\n",
      "Processing 10/30/2022\n",
      "Saved data to arrival_10_30_2022.csv\n",
      "Processing 10/31/2022\n",
      "Saved data to arrival_10_31_2022.csv\n",
      "Processing 11/01/2022\n",
      "Saved data to arrival_11_01_2022.csv\n",
      "Processing 11/02/2022\n",
      "Saved data to arrival_11_02_2022.csv\n",
      "Processing 11/03/2022\n",
      "Saved data to arrival_11_03_2022.csv\n",
      "Processing 11/04/2022\n",
      "Saved data to arrival_11_04_2022.csv\n",
      "Processing 11/05/2022\n",
      "Saved data to arrival_11_05_2022.csv\n",
      "Processing 11/06/2022\n",
      "Saved data to arrival_11_06_2022.csv\n",
      "Processing 11/07/2022\n",
      "Saved data to arrival_11_07_2022.csv\n",
      "Processing 11/08/2022\n",
      "Saved data to arrival_11_08_2022.csv\n",
      "Processing 11/09/2022\n",
      "Saved data to arrival_11_09_2022.csv\n",
      "Processing 11/10/2022\n",
      "Saved data to arrival_11_10_2022.csv\n",
      "Processing 11/11/2022\n",
      "Saved data to arrival_11_11_2022.csv\n",
      "Processing 11/12/2022\n",
      "Saved data to arrival_11_12_2022.csv\n",
      "Processing 11/13/2022\n",
      "Saved data to arrival_11_13_2022.csv\n",
      "Processing 11/14/2022\n",
      "Saved data to arrival_11_14_2022.csv\n",
      "Processing 11/15/2022\n",
      "Saved data to arrival_11_15_2022.csv\n",
      "Processing 11/16/2022\n",
      "Saved data to arrival_11_16_2022.csv\n",
      "Processing 11/17/2022\n",
      "Saved data to arrival_11_17_2022.csv\n",
      "Processing 11/18/2022\n",
      "Saved data to arrival_11_18_2022.csv\n",
      "Processing 11/19/2022\n",
      "Saved data to arrival_11_19_2022.csv\n",
      "Processing 11/20/2022\n",
      "Saved data to arrival_11_20_2022.csv\n",
      "Processing 11/21/2022\n",
      "Saved data to arrival_11_21_2022.csv\n",
      "Processing 11/22/2022\n",
      "Saved data to arrival_11_22_2022.csv\n",
      "Processing 11/23/2022\n",
      "Saved data to arrival_11_23_2022.csv\n",
      "Processing 11/24/2022\n",
      "Saved data to arrival_11_24_2022.csv\n",
      "Processing 11/25/2022\n",
      "Saved data to arrival_11_25_2022.csv\n",
      "Processing 11/26/2022\n",
      "Saved data to arrival_11_26_2022.csv\n",
      "Processing 11/27/2022\n",
      "Saved data to arrival_11_27_2022.csv\n",
      "Processing 11/28/2022\n",
      "Saved data to arrival_11_28_2022.csv\n",
      "Processing 11/29/2022\n",
      "Saved data to arrival_11_29_2022.csv\n",
      "Processing 11/30/2022\n",
      "Saved data to arrival_11_30_2022.csv\n",
      "Processing 12/01/2022\n",
      "Saved data to arrival_12_01_2022.csv\n",
      "Processing 12/02/2022\n",
      "Saved data to arrival_12_02_2022.csv\n",
      "Processing 12/03/2022\n",
      "Saved data to arrival_12_03_2022.csv\n",
      "Processing 12/04/2022\n",
      "Saved data to arrival_12_04_2022.csv\n",
      "Processing 12/05/2022\n",
      "Saved data to arrival_12_05_2022.csv\n",
      "Processing 12/06/2022\n",
      "Saved data to arrival_12_06_2022.csv\n",
      "Processing 12/07/2022\n",
      "Saved data to arrival_12_07_2022.csv\n",
      "Processing 12/08/2022\n",
      "Saved data to arrival_12_08_2022.csv\n",
      "Processing 12/09/2022\n",
      "Saved data to arrival_12_09_2022.csv\n",
      "Processing 12/10/2022\n",
      "Saved data to arrival_12_10_2022.csv\n",
      "Processing 12/11/2022\n",
      "Saved data to arrival_12_11_2022.csv\n",
      "Processing 12/12/2022\n",
      "Saved data to arrival_12_12_2022.csv\n",
      "Processing 12/13/2022\n",
      "Saved data to arrival_12_13_2022.csv\n",
      "Processing 12/14/2022\n",
      "Saved data to arrival_12_14_2022.csv\n",
      "Processing 12/15/2022\n",
      "Saved data to arrival_12_15_2022.csv\n",
      "Processing 12/16/2022\n",
      "Saved data to arrival_12_16_2022.csv\n",
      "Processing 12/17/2022\n",
      "Saved data to arrival_12_17_2022.csv\n",
      "Processing 12/18/2022\n",
      "Saved data to arrival_12_18_2022.csv\n",
      "Processing 12/19/2022\n",
      "Saved data to arrival_12_19_2022.csv\n",
      "Processing 12/20/2022\n",
      "Saved data to arrival_12_20_2022.csv\n",
      "Processing 12/21/2022\n",
      "Saved data to arrival_12_21_2022.csv\n",
      "Processing 12/22/2022\n",
      "Saved data to arrival_12_22_2022.csv\n",
      "Processing 12/23/2022\n",
      "Saved data to arrival_12_23_2022.csv\n",
      "Processing 12/24/2022\n",
      "Saved data to arrival_12_24_2022.csv\n",
      "Processing 12/25/2022\n",
      "Saved data to arrival_12_25_2022.csv\n",
      "Processing 12/26/2022\n",
      "Saved data to arrival_12_26_2022.csv\n",
      "Processing 12/27/2022\n",
      "Saved data to arrival_12_27_2022.csv\n",
      "Processing 12/28/2022\n",
      "Saved data to arrival_12_28_2022.csv\n",
      "Processing 12/29/2022\n",
      "Saved data to arrival_12_29_2022.csv\n",
      "Processing 12/30/2022\n",
      "Saved data to arrival_12_30_2022.csv\n",
      "Processing 12/31/2022\n",
      "Saved data to arrival_12_31_2022.csv\n",
      "Done with sincere extraction for January 2025!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "driver.get(\"https://kalimatimarket.gov.np/\")\n",
    "\n",
    "start_date = datetime.strptime('01/01/2022', '%m/%d/%Y')\n",
    "end_date = datetime.strptime('12/31/2022', '%m/%d/%Y')\n",
    "\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    target_date = current_date.strftime('%m/%d/%Y')\n",
    "    filename_date = target_date.replace('/', '_')\n",
    "    filename = f'arrival_{filename_date}.csv'\n",
    "    print(f\"Processing {target_date}\")\n",
    "\n",
    "    try:\n",
    "        # Find and set date input\n",
    "        date_input = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"input[type='text'], input[type='date']\")))\n",
    "        date_input.clear()\n",
    "        date_input.send_keys(target_date)\n",
    "\n",
    "        # Click the \"à¤†à¤—à¤®à¤¨ à¤¡à¤¾à¤Ÿà¤¾ à¤œà¤¾à¤à¤šà¥à¤¨à¥à¤¹à¥‹à¤¸à¥\" button\n",
    "        arrival_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(),'à¤®à¥‚à¤²à¥à¤¯à¤¹à¤°à¥‚ à¤œà¤¾à¤à¤š à¤—à¤°à¥à¤¨à¥à¤¹à¥‹à¤¸à¥')]\")))\n",
    "        arrival_button.click()\n",
    "\n",
    "        # Wait up to 20 seconds for table to update (avoid stale table)\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"table\")))\n",
    "\n",
    "        # Now, RE-FIND all rows fresh for each loop\n",
    "        time.sleep(2)  # Give extra time for asynchronous JS data load\n",
    "\n",
    "        table_data = []\n",
    "        rows = driver.find_elements(By.CSS_SELECTOR, \"table tr\")  # <--- Fresh locate!\n",
    "        for row in rows:\n",
    "            cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            if cols:\n",
    "                table_data.append([col.text.strip() for col in cols])\n",
    "\n",
    "        # Check if there is any actual, meaningful data (not just empty rows)\n",
    "        data_exists = any(any(cell for cell in row) for row in table_data)\n",
    "        if data_exists:\n",
    "            with open(filename, \"w\", newline='', encoding='utf-8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                for row in table_data:\n",
    "                    writer.writerow(row)\n",
    "            print(f\"Saved data to {filename}\")\n",
    "        else:\n",
    "            print(f\"No arrival data for {target_date} (table was blank or only headers)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on {target_date}: {e}\")\n",
    "\n",
    "    current_date += timedelta(days=1)\n",
    "    time.sleep(1)\n",
    "\n",
    "driver.quit()\n",
    "print(\"Done with sincere extraction for January 2025!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ff0e09-7330-4c3f-a858-620e20eb19d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Working folder: D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\n",
      "âœ… Found 367 CSV files to merge\n",
      "âœ… Merging completed successfully!\n",
      "ðŸ’¾ File saved as: D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\\arrival_2022_full.csv\n",
      "Final shape: (36212, 6)\n",
      "         Date             commodity    unit    minimum    maximum  \\\n",
      "0  2022-01-01  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤­à¤¾à¤°à¤¤à¥€à¤¯)    à¤•à¥‡à¤œà¥€  à¤°à¥‚ à¥§à¥¦à¥§.à¥¦à¥¦  à¤°à¥‚ à¥§à¥¦à¥§.à¥¦à¥¦   \n",
      "1  2022-01-01    à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤²à¥‹à¤•à¤²)  à¤•à¥‡.à¤œà¥€.   à¤°à¥‚ à¥ªà¥¦.à¥¦à¥¦   à¤°à¥‚ à¥«à¥¦.à¥¦à¥¦   \n",
      "2  2022-01-01    à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤Ÿà¤¨à¥‡à¤²)   à¤•à¥‡ à¤œà¥€   à¤°à¥‚ à¥«à¥¦.à¥¦à¥¦   à¤°à¥‚ à¥¬à¥¦.à¥¦à¥¦   \n",
      "3  2022-01-01  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤­à¤¾à¤°à¤¤à¥€à¤¯)   à¤•à¥‡ à¤œà¥€   à¤°à¥‚ à¥«à¥«.à¥¦à¥¦   à¤°à¥‚ à¥¬à¥«.à¥¦à¥¦   \n",
      "4  2022-01-01    à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤¤à¤°à¤¾à¤ˆ)   à¤•à¥‡ à¤œà¥€   à¤°à¥‚ à¥¬à¥¦.à¥¦à¥¦   à¤°à¥‚ à¥­à¥¦.à¥¦à¥¦   \n",
      "\n",
      "  average_price  \n",
      "0     à¤°à¥‚ à¥§à¥¦à¥§.à¥¦à¥¦  \n",
      "1      à¤°à¥‚ à¥ªà¥«.à¥¦à¥¦  \n",
      "2      à¤°à¥‚ à¥«à¥«.à¥¦à¥¦  \n",
      "3      à¤°à¥‚ à¥¬à¥¦.à¥¦à¥¦  \n",
      "4      à¤°à¥‚ à¥¬à¥«.à¥¦à¥¦  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20552\\257274747.py:37: DtypeWarning: Columns (2,3,4,8,10,15,18,20,21,24,26,27,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 1: Automatically detect current working directory\n",
    "# ---------------------------------------------------------------\n",
    "folder = os.getcwd()\n",
    "print(f\"ðŸ“‚ Working folder: {folder}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 2: Find all CSV files starting with 'arrival_'\n",
    "# ---------------------------------------------------------------\n",
    "csv_files = sorted(glob(os.path.join(folder, \"arrival_*.csv\")))\n",
    "\n",
    "print(f\"âœ… Found {len(csv_files)} CSV files to merge\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 3: Read, clean, and standardize each CSV\n",
    "# ---------------------------------------------------------------\n",
    "merged_data = []\n",
    "\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        # Extract date from filename, e.g. 'arrival_02_15_2022.csv' â†’ '2022-02-15'\n",
    "        basename = os.path.basename(file)\n",
    "        date_str = basename.replace(\"arrival_\", \"\").replace(\".csv\", \"\")\n",
    "        # handle formats like arrival_1_2_2022.csv as well\n",
    "        parts = date_str.split(\"_\")\n",
    "        if len(parts) == 3:\n",
    "            month, day, year = parts\n",
    "            formatted_date = f\"{year}-{int(month):02d}-{int(day):02d}\"\n",
    "        else:\n",
    "            formatted_date = None\n",
    "        \n",
    "        # Read CSV\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        # Standardize columns (in case names vary or missing)\n",
    "        df.columns = [col.strip().lower() for col in df.columns]\n",
    "        \n",
    "        # Select only first 6 columns if extra exist\n",
    "        df = df.iloc[:, :6]\n",
    "        \n",
    "        # Assign correct column names\n",
    "        df.columns = ['commodity', 'unit', 'minimum', 'maximum', 'average_price', 'extra'][:len(df.columns)]\n",
    "        \n",
    "        # Ensure required columns exist (fill missing)\n",
    "        for col in ['commodity', 'unit', 'minimum', 'maximum', 'average_price']:\n",
    "            if col not in df.columns:\n",
    "                df[col] = None\n",
    "        \n",
    "        # Add Date column\n",
    "        df['Date'] = formatted_date\n",
    "        \n",
    "        # Reorder columns\n",
    "        df = df[['Date', 'commodity', 'unit', 'minimum', 'maximum', 'average_price']]\n",
    "        \n",
    "        # Append to list\n",
    "        merged_data.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error reading {file}: {e}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 4: Merge all DataFrames\n",
    "# ---------------------------------------------------------------\n",
    "final_df = pd.concat(merged_data, ignore_index=True)\n",
    "final_df = final_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 5: Save merged CSV\n",
    "# ---------------------------------------------------------------\n",
    "output_file = os.path.join(folder, \"arrival_2022_full.csv\")\n",
    "final_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"âœ… Merging completed successfully!\")\n",
    "print(f\"ðŸ’¾ File saved as: {output_file}\")\n",
    "print(\"Final shape:\", final_df.shape)\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d9027e-1290-43d3-8d3a-a56c612aeb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Current working directory: D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\n",
      "âœ… Found 366 CSV files to merge\n",
      "âš ï¸ Error reading D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\\arrival_02_26_2022.csv: \"['unit', 'minimum', 'maximum', 'average_price'] not in index\"\n",
      "âš ï¸ Error reading D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\\arrival_03_04_2022.csv: \"['unit', 'minimum', 'maximum', 'average_price'] not in index\"\n",
      "âš ï¸ Error reading D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\\arrival_05_13_2022.csv: \"['unit', 'minimum', 'maximum', 'average_price'] not in index\"\n",
      "âš ï¸ Error reading D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\\arrival_11_20_2022.csv: \"['unit', 'minimum', 'maximum', 'average_price'] not in index\"\n",
      "âš ï¸ Error reading D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\\arrival_merge.csv: \"['average_price'] not in index\"\n",
      "âœ… Merge complete!\n",
      "ðŸ’¾ Saved as: D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\\arrival_2022_full.csv\n",
      "Final shape: (35084, 6)\n",
      "         Date             commodity    unit  minimum  maximum  average_price\n",
      "0  2022-01-01  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.      NaN      NaN            NaN\n",
      "1  2022-01-01  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤­à¤¾à¤°à¤¤à¥€à¤¯)    à¤•à¥‡à¤œà¥€      NaN      NaN            NaN\n",
      "2  2022-01-01    à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤²à¥‹à¤•à¤²)  à¤•à¥‡.à¤œà¥€.      NaN      NaN            NaN\n",
      "3  2022-01-01    à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤Ÿà¤¨à¥‡à¤²)   à¤•à¥‡ à¤œà¥€      NaN      NaN            NaN\n",
      "4  2022-01-01  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤­à¤¾à¤°à¤¤à¥€à¤¯)   à¤•à¥‡ à¤œà¥€      NaN      NaN            NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 1: Detect current working directory\n",
    "# ---------------------------------------------------------------\n",
    "folder = os.getcwd()\n",
    "print(f\"ðŸ“‚ Current working directory: {folder}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 2: Get all arrival CSV files\n",
    "# ---------------------------------------------------------------\n",
    "csv_files = sorted(glob(os.path.join(folder, \"arrival_*.csv\")))\n",
    "print(f\"âœ… Found {len(csv_files)} CSV files to merge\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 3: Define correct column names\n",
    "# ---------------------------------------------------------------\n",
    "columns = ['commodity', 'unit', 'minimum', 'maximum', 'average_price']\n",
    "\n",
    "merged_data = []\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 4: Read each file (no header) and add date from filename\n",
    "# ---------------------------------------------------------------\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        # Extract date from filename, e.g. \"arrival_03_15_2022.csv\" â†’ \"2022-03-15\"\n",
    "        basename = os.path.basename(file)\n",
    "        date_str = basename.replace(\"arrival_\", \"\").replace(\".csv\", \"\")\n",
    "        parts = date_str.split(\"_\")\n",
    "        if len(parts) == 3:\n",
    "            month, day, year = parts\n",
    "            formatted_date = f\"{year}-{int(month):02d}-{int(day):02d}\"\n",
    "        else:\n",
    "            formatted_date = None\n",
    "\n",
    "        # Read CSV with no header\n",
    "        df = pd.read_csv(file, header=None)\n",
    "\n",
    "        # Assign column names manually\n",
    "        df.columns = columns[:len(df.columns)]\n",
    "\n",
    "        # Add Date column\n",
    "        df['Date'] = formatted_date\n",
    "\n",
    "        # Reorder columns (Date first)\n",
    "        df = df[['Date'] + columns]\n",
    "\n",
    "        merged_data.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error reading {file}: {e}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 5: Merge all data into one DataFrame\n",
    "# ---------------------------------------------------------------\n",
    "final_df = pd.concat(merged_data, ignore_index=True)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 6: Clean & Save\n",
    "# ---------------------------------------------------------------\n",
    "final_df = final_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Convert numeric columns if needed\n",
    "for col in ['minimum', 'maximum', 'average_price']:\n",
    "    final_df[col] = pd.to_numeric(final_df[col], errors='coerce')\n",
    "\n",
    "# Save as single CSV\n",
    "output_file = os.path.join(folder, \"arrival_2022_full.csv\")\n",
    "final_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"âœ… Merge complete!\")\n",
    "print(f\"ðŸ’¾ Saved as: {output_file}\")\n",
    "print(\"Final shape:\", final_df.shape)\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ba202fa-8dc2-4efb-a279-d05c71309d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Current working directory: D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\n",
      "âœ… Found 365 CSV files to merge\n",
      "âœ… Merge complete!\n",
      "ðŸ’¾ Saved as: D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\\arrival_2022_full.csv\n",
      "Final shape: (35088, 6)\n",
      "         Date              commodity    unit  minimum  maximum  average_price\n",
      "0  2022-01-01   à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.      NaN      NaN            NaN\n",
      "1  2022-01-01   à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤­à¤¾à¤°à¤¤à¥€à¤¯)    à¤•à¥‡à¤œà¥€      NaN      NaN            NaN\n",
      "2  2022-01-01     à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤²à¥‹à¤•à¤²)  à¤•à¥‡.à¤œà¥€.      NaN      NaN            NaN\n",
      "3  2022-01-01     à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤Ÿà¤¨à¥‡à¤²)   à¤•à¥‡ à¤œà¥€      NaN      NaN            NaN\n",
      "4  2022-01-01   à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤­à¤¾à¤°à¤¤à¥€à¤¯)   à¤•à¥‡ à¤œà¥€      NaN      NaN            NaN\n",
      "5  2022-01-01     à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤¤à¤°à¤¾à¤ˆ)   à¤•à¥‡ à¤œà¥€      NaN      NaN            NaN\n",
      "6  2022-01-01               à¤†à¤²à¥ à¤°à¤¾à¤¤à¥‹  à¤•à¥‡.à¤œà¥€.      NaN      NaN            NaN\n",
      "7  2022-01-01       à¤†à¤²à¥ à¤°à¤¾à¤¤à¥‹(à¤­à¤¾à¤°à¤¤à¥€à¤¯)   à¤•à¥‡ à¤œà¥€      NaN      NaN            NaN\n",
      "8  2022-01-01               à¤†à¤²à¥ à¤¸à¥‡à¤¤à¥‹  à¤•à¥‡.à¤œà¥€.      NaN      NaN            NaN\n",
      "9  2022-01-01  à¤ªà¥à¤¯à¤¾à¤œ à¤¸à¥à¤•à¥‡à¤•à¥‹ (à¤­à¤¾à¤°à¤¤à¥€à¤¯)  à¤•à¥‡.à¤œà¥€.      NaN      NaN            NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 1: Working directory (your notebook folder)\n",
    "# ---------------------------------------------------------------\n",
    "folder = os.getcwd()\n",
    "print(f\"ðŸ“‚ Current working directory: {folder}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 2: Get all CSV files (skip already merged ones)\n",
    "# ---------------------------------------------------------------\n",
    "csv_files = sorted(glob(os.path.join(folder, \"arrival_*.csv\")))\n",
    "csv_files = [f for f in csv_files if \"merge\" not in f and \"full\" not in f]\n",
    "\n",
    "print(f\"âœ… Found {len(csv_files)} CSV files to merge\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 3: Define standard column names\n",
    "# ---------------------------------------------------------------\n",
    "standard_cols = ['commodity', 'unit', 'minimum', 'maximum', 'average_price']\n",
    "\n",
    "merged_data = []\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 4: Loop through all files\n",
    "# ---------------------------------------------------------------\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        # Extract date from filename\n",
    "        basename = os.path.basename(file)\n",
    "        date_str = basename.replace(\"arrival_\", \"\").replace(\".csv\", \"\")\n",
    "        parts = date_str.split(\"_\")\n",
    "        if len(parts) == 3:\n",
    "            month, day, year = parts\n",
    "            formatted_date = f\"{year}-{int(month):02d}-{int(day):02d}\"\n",
    "        else:\n",
    "            formatted_date = None\n",
    "\n",
    "        # Try reading with flexible delimiters\n",
    "        try:\n",
    "            df = pd.read_csv(file, header=None, engine='python')\n",
    "        except:\n",
    "            df = pd.read_csv(file, header=None, delimiter=';', engine='python')\n",
    "        \n",
    "        # Drop completely empty columns\n",
    "        df = df.dropna(axis=1, how='all')\n",
    "        \n",
    "        # Keep only up to 5 columns (extra columns are garbage)\n",
    "        df = df.iloc[:, :5]\n",
    "\n",
    "        # Assign standard column names\n",
    "        df.columns = standard_cols[:len(df.columns)]\n",
    "\n",
    "        # Fill missing columns if file had fewer columns\n",
    "        for col in standard_cols:\n",
    "            if col not in df.columns:\n",
    "                df[col] = None\n",
    "\n",
    "        # Add date column\n",
    "        df['Date'] = formatted_date\n",
    "\n",
    "        # Reorder\n",
    "        df = df[['Date'] + standard_cols]\n",
    "\n",
    "        # Clean up whitespace in text columns\n",
    "        for col in ['commodity', 'unit']:\n",
    "            df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "        merged_data.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error reading {file}: {e}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 5: Combine all data\n",
    "# ---------------------------------------------------------------\n",
    "final_df = pd.concat(merged_data, ignore_index=True)\n",
    "final_df = final_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Convert numeric columns to proper dtype\n",
    "for col in ['minimum', 'maximum', 'average_price']:\n",
    "    final_df[col] = pd.to_numeric(final_df[col], errors='coerce')\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 6: Save final merged CSV\n",
    "# ---------------------------------------------------------------\n",
    "output_file = os.path.join(folder, \"arrival_2022_full.csv\")\n",
    "final_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"âœ… Merge complete!\")\n",
    "print(f\"ðŸ’¾ Saved as: {output_file}\")\n",
    "print(\"Final shape:\", final_df.shape)\n",
    "print(final_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad3dbe8e-41c9-4d77-8458-5f44e3c368cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Current working directory: D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\n",
      "âœ… Found 365 CSV files to merge\n",
      "âœ… Merge complete!\n",
      "ðŸ’¾ Saved as: D:\\Data Science\\First Semester\\Machine Learning\\Group Project\\Kalimati\\arrival_2022_full.csv\n",
      "Final shape: (35088, 6)\n",
      "         Date              commodity    unit    minimum    maximum  \\\n",
      "0  2022-01-01   à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.  à¤°à¥‚ à¥§à¥§à¥¦.à¥¦à¥¦  à¤°à¥‚ à¥§à¥¨à¥¦.à¥¦à¥¦   \n",
      "1  2022-01-01   à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤­à¤¾à¤°à¤¤à¥€à¤¯)    à¤•à¥‡à¤œà¥€  à¤°à¥‚ à¥§à¥¦à¥§.à¥¦à¥¦  à¤°à¥‚ à¥§à¥¦à¥§.à¥¦à¥¦   \n",
      "2  2022-01-01     à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤²à¥‹à¤•à¤²)  à¤•à¥‡.à¤œà¥€.   à¤°à¥‚ à¥ªà¥¦.à¥¦à¥¦   à¤°à¥‚ à¥«à¥¦.à¥¦à¥¦   \n",
      "3  2022-01-01     à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤Ÿà¤¨à¥‡à¤²)   à¤•à¥‡ à¤œà¥€   à¤°à¥‚ à¥«à¥¦.à¥¦à¥¦   à¤°à¥‚ à¥¬à¥¦.à¥¦à¥¦   \n",
      "4  2022-01-01   à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤­à¤¾à¤°à¤¤à¥€à¤¯)   à¤•à¥‡ à¤œà¥€   à¤°à¥‚ à¥«à¥«.à¥¦à¥¦   à¤°à¥‚ à¥¬à¥«.à¥¦à¥¦   \n",
      "5  2022-01-01     à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤¤à¤°à¤¾à¤ˆ)   à¤•à¥‡ à¤œà¥€   à¤°à¥‚ à¥¬à¥¦.à¥¦à¥¦   à¤°à¥‚ à¥­à¥¦.à¥¦à¥¦   \n",
      "6  2022-01-01               à¤†à¤²à¥ à¤°à¤¾à¤¤à¥‹  à¤•à¥‡.à¤œà¥€.   à¤°à¥‚ à¥©à¥¨.à¥¦à¥¦   à¤°à¥‚ à¥©à¥¬.à¥¦à¥¦   \n",
      "7  2022-01-01       à¤†à¤²à¥ à¤°à¤¾à¤¤à¥‹(à¤­à¤¾à¤°à¤¤à¥€à¤¯)   à¤•à¥‡ à¤œà¥€   à¤°à¥‚ à¥¨à¥«.à¥¦à¥¦   à¤°à¥‚ à¥©à¥¦.à¥¦à¥¦   \n",
      "8  2022-01-01               à¤†à¤²à¥ à¤¸à¥‡à¤¤à¥‹  à¤•à¥‡.à¤œà¥€.   à¤°à¥‚ à¥¨à¥¨.à¥¦à¥¦   à¤°à¥‚ à¥¨à¥«.à¥¦à¥¦   \n",
      "9  2022-01-01  à¤ªà¥à¤¯à¤¾à¤œ à¤¸à¥à¤•à¥‡à¤•à¥‹ (à¤­à¤¾à¤°à¤¤à¥€à¤¯)  à¤•à¥‡.à¤œà¥€.   à¤°à¥‚ à¥«à¥¨.à¥¦à¥¦   à¤°à¥‚ à¥«à¥«.à¥¦à¥¦   \n",
      "\n",
      "  average_price  \n",
      "0     à¤°à¥‚ à¥§à¥§à¥«.à¥¦à¥¦  \n",
      "1     à¤°à¥‚ à¥§à¥¦à¥§.à¥¦à¥¦  \n",
      "2      à¤°à¥‚ à¥ªà¥«.à¥¦à¥¦  \n",
      "3      à¤°à¥‚ à¥«à¥«.à¥¦à¥¦  \n",
      "4      à¤°à¥‚ à¥¬à¥¦.à¥¦à¥¦  \n",
      "5      à¤°à¥‚ à¥¬à¥«.à¥¦à¥¦  \n",
      "6      à¤°à¥‚ à¥©à¥©.à¥¬à¥¦  \n",
      "7      à¤°à¥‚ à¥¨à¥­.à¥«à¥¦  \n",
      "8      à¤°à¥‚ à¥¨à¥©.à¥«à¥¦  \n",
      "9      à¤°à¥‚ à¥«à¥©.à¥¬à¥¦  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 1: Working directory (your notebook folder)\n",
    "# ---------------------------------------------------------------\n",
    "folder = os.getcwd()\n",
    "print(f\"ðŸ“‚ Current working directory: {folder}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 2: Get all CSV files (skip already merged ones)\n",
    "# ---------------------------------------------------------------\n",
    "csv_files = sorted(glob(os.path.join(folder, \"arrival_*.csv\")))\n",
    "csv_files = [f for f in csv_files if \"merge\" not in f and \"full\" not in f]\n",
    "\n",
    "print(f\"âœ… Found {len(csv_files)} CSV files to merge\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 3: Define standard column names\n",
    "# ---------------------------------------------------------------\n",
    "standard_cols = ['commodity', 'unit', 'minimum', 'maximum', 'average_price']\n",
    "\n",
    "merged_data = []\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 4: Loop through all files\n",
    "# ---------------------------------------------------------------\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        # Extract date from filename\n",
    "        basename = os.path.basename(file)\n",
    "        date_str = basename.replace(\"arrival_\", \"\").replace(\".csv\", \"\")\n",
    "        parts = date_str.split(\"_\")\n",
    "        if len(parts) == 3:\n",
    "            month, day, year = parts\n",
    "            formatted_date = f\"{year}-{int(month):02d}-{int(day):02d}\"\n",
    "        else:\n",
    "            formatted_date = None\n",
    "\n",
    "        # Try reading with flexible delimiters\n",
    "        try:\n",
    "            df = pd.read_csv(file, header=None, engine='python')\n",
    "        except:\n",
    "            df = pd.read_csv(file, header=None, delimiter=';', engine='python')\n",
    "        \n",
    "        # Drop completely empty columns\n",
    "        df = df.dropna(axis=1, how='all')\n",
    "        \n",
    "        # Keep only up to 5 columns (ignore extra garbage)\n",
    "        df = df.iloc[:, :5]\n",
    "\n",
    "        # Assign standard column names\n",
    "        df.columns = standard_cols[:len(df.columns)]\n",
    "\n",
    "        # Fill missing columns if file had fewer columns\n",
    "        for col in standard_cols:\n",
    "            if col not in df.columns:\n",
    "                df[col] = None\n",
    "\n",
    "        # Add Date column\n",
    "        df['Date'] = formatted_date\n",
    "\n",
    "        # Reorder columns\n",
    "        df = df[['Date'] + standard_cols]\n",
    "\n",
    "        # Clean text columns\n",
    "        for col in ['commodity', 'unit', 'minimum', 'maximum', 'average_price']:\n",
    "            df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "        merged_data.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error reading {file}: {e}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 5: Combine all dataframes\n",
    "# ---------------------------------------------------------------\n",
    "final_df = pd.concat(merged_data, ignore_index=True)\n",
    "final_df = final_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# STEP 6: Save merged CSV (keep as text)\n",
    "# ---------------------------------------------------------------\n",
    "output_file = os.path.join(folder, \"arrival_2022_full.csv\")\n",
    "final_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"âœ… Merge complete!\")\n",
    "print(f\"ðŸ’¾ Saved as: {output_file}\")\n",
    "print(\"Final shape:\", final_df.shape)\n",
    "print(final_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11f9cd87-7f6c-43e8-b6d9-5d005c6d8b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>commodity</th>\n",
       "      <th>unit</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>à¤°à¥‚ à¥§à¥§à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥§à¥¨à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥§à¥§à¥«.à¥¦à¥¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤­à¤¾à¤°à¤¤à¥€à¤¯)</td>\n",
       "      <td>à¤•à¥‡à¤œà¥€</td>\n",
       "      <td>à¤°à¥‚ à¥§à¥¦à¥§.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥§à¥¦à¥§.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥§à¥¦à¥§.à¥¦à¥¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤²à¥‹à¤•à¤²)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>à¤°à¥‚ à¥ªà¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥«à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥ªà¥«.à¥¦à¥¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤Ÿà¤¨à¥‡à¤²)</td>\n",
       "      <td>à¤•à¥‡ à¤œà¥€</td>\n",
       "      <td>à¤°à¥‚ à¥«à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥¬à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥«à¥«.à¥¦à¥¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤­à¤¾à¤°à¤¤à¥€à¤¯)</td>\n",
       "      <td>à¤•à¥‡ à¤œà¥€</td>\n",
       "      <td>à¤°à¥‚ à¥«à¥«.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥¬à¥«.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥¬à¥¦.à¥¦à¥¦</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date             commodity    unit    minimum    maximum  \\\n",
       "0  2022-01-01  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.  à¤°à¥‚ à¥§à¥§à¥¦.à¥¦à¥¦  à¤°à¥‚ à¥§à¥¨à¥¦.à¥¦à¥¦   \n",
       "1  2022-01-01  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤­à¤¾à¤°à¤¤à¥€à¤¯)    à¤•à¥‡à¤œà¥€  à¤°à¥‚ à¥§à¥¦à¥§.à¥¦à¥¦  à¤°à¥‚ à¥§à¥¦à¥§.à¥¦à¥¦   \n",
       "2  2022-01-01    à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤²à¥‹à¤•à¤²)  à¤•à¥‡.à¤œà¥€.   à¤°à¥‚ à¥ªà¥¦.à¥¦à¥¦   à¤°à¥‚ à¥«à¥¦.à¥¦à¥¦   \n",
       "3  2022-01-01    à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤Ÿà¤¨à¥‡à¤²)   à¤•à¥‡ à¤œà¥€   à¤°à¥‚ à¥«à¥¦.à¥¦à¥¦   à¤°à¥‚ à¥¬à¥¦.à¥¦à¥¦   \n",
       "4  2022-01-01  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤¸à¤¾à¤¨à¥‹(à¤­à¤¾à¤°à¤¤à¥€à¤¯)   à¤•à¥‡ à¤œà¥€   à¤°à¥‚ à¥«à¥«.à¥¦à¥¦   à¤°à¥‚ à¥¬à¥«.à¥¦à¥¦   \n",
       "\n",
       "  average_price  \n",
       "0     à¤°à¥‚ à¥§à¥§à¥«.à¥¦à¥¦  \n",
       "1     à¤°à¥‚ à¥§à¥¦à¥§.à¥¦à¥¦  \n",
       "2      à¤°à¥‚ à¥ªà¥«.à¥¦à¥¦  \n",
       "3      à¤°à¥‚ à¥«à¥«.à¥¦à¥¦  \n",
       "4      à¤°à¥‚ à¥¬à¥¦.à¥¦à¥¦  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('arrival_2022_full.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b75d4f2-f7ab-42b7-92da-f289937b6967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>commodity</th>\n",
       "      <th>unit</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35083</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>à¤¤à¤¾à¤œà¤¾ à¤®à¤¾à¤›à¤¾(à¤°à¤¹à¥)</td>\n",
       "      <td>à¤•à¥‡ à¤œà¥€</td>\n",
       "      <td>à¤°à¥‚ à¥©à¥¨à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥©à¥ªà¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥©à¥©à¥¦.à¥¦à¥¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35084</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>à¤¤à¤¾à¤œà¤¾ à¤®à¤¾à¤›à¤¾(à¤¬à¤šà¥à¤µà¤¾)</td>\n",
       "      <td>à¤•à¥‡ à¤œà¥€</td>\n",
       "      <td>à¤°à¥‚ à¥¨à¥ªà¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥¨à¥«à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥¨à¥ªà¥«.à¥¦à¥¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35085</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>à¤¤à¤¾à¤œà¤¾ à¤®à¤¾à¤›à¤¾(à¤›à¤¡à¥€)</td>\n",
       "      <td>à¤•à¥‡ à¤œà¥€</td>\n",
       "      <td>à¤°à¥‚ à¥¨à¥«à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥¨à¥¬à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥¨à¥«à¥«.à¥¦à¥¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35086</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>à¤¤à¤¾à¤œà¤¾ à¤®à¤¾à¤›à¤¾(à¤®à¥à¤‚à¤—à¤°à¥€)</td>\n",
       "      <td>à¤•à¥‡ à¤œà¥€</td>\n",
       "      <td>à¤°à¥‚ à¥¨à¥¬à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥¨à¥®à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥¨à¥­à¥¦.à¥¦à¥¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35087</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>à¤°à¥à¤– à¤Ÿà¤®à¤¾à¤Ÿà¤°</td>\n",
       "      <td>à¤•à¥‡à¤œà¥€</td>\n",
       "      <td>à¤°à¥‚ à¥­à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥®à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥­à¥«.à¥¦à¥¦</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date          commodity   unit    minimum    maximum  \\\n",
       "35083  2022-12-31     à¤¤à¤¾à¤œà¤¾ à¤®à¤¾à¤›à¤¾(à¤°à¤¹à¥)  à¤•à¥‡ à¤œà¥€  à¤°à¥‚ à¥©à¥¨à¥¦.à¥¦à¥¦  à¤°à¥‚ à¥©à¥ªà¥¦.à¥¦à¥¦   \n",
       "35084  2022-12-31   à¤¤à¤¾à¤œà¤¾ à¤®à¤¾à¤›à¤¾(à¤¬à¤šà¥à¤µà¤¾)  à¤•à¥‡ à¤œà¥€  à¤°à¥‚ à¥¨à¥ªà¥¦.à¥¦à¥¦  à¤°à¥‚ à¥¨à¥«à¥¦.à¥¦à¥¦   \n",
       "35085  2022-12-31     à¤¤à¤¾à¤œà¤¾ à¤®à¤¾à¤›à¤¾(à¤›à¤¡à¥€)  à¤•à¥‡ à¤œà¥€  à¤°à¥‚ à¥¨à¥«à¥¦.à¥¦à¥¦  à¤°à¥‚ à¥¨à¥¬à¥¦.à¥¦à¥¦   \n",
       "35086  2022-12-31  à¤¤à¤¾à¤œà¤¾ à¤®à¤¾à¤›à¤¾(à¤®à¥à¤‚à¤—à¤°à¥€)  à¤•à¥‡ à¤œà¥€  à¤°à¥‚ à¥¨à¥¬à¥¦.à¥¦à¥¦  à¤°à¥‚ à¥¨à¥®à¥¦.à¥¦à¥¦   \n",
       "35087  2022-12-31          à¤°à¥à¤– à¤Ÿà¤®à¤¾à¤Ÿà¤°   à¤•à¥‡à¤œà¥€   à¤°à¥‚ à¥­à¥¦.à¥¦à¥¦   à¤°à¥‚ à¥®à¥¦.à¥¦à¥¦   \n",
       "\n",
       "      average_price  \n",
       "35083     à¤°à¥‚ à¥©à¥©à¥¦.à¥¦à¥¦  \n",
       "35084     à¤°à¥‚ à¥¨à¥ªà¥«.à¥¦à¥¦  \n",
       "35085     à¤°à¥‚ à¥¨à¥«à¥«.à¥¦à¥¦  \n",
       "35086     à¤°à¥‚ à¥¨à¥­à¥¦.à¥¦à¥¦  \n",
       "35087      à¤°à¥‚ à¥­à¥«.à¥¦à¥¦  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c465fc5-9d95-4739-b4ab-2bd7cc4ad02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tomato_big = df[df['commodity']=='à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d984c909-3a73-4f94-84c6-9ea7cbfd0b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>commodity</th>\n",
       "      <th>unit</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>à¤°à¥‚ à¥§à¥§à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥§à¥¨à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥§à¥§à¥«.à¥¦à¥¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>à¤°à¥‚ à¥§à¥§à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥§à¥¨à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥§à¥§à¥«.à¥¦à¥¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>à¤°à¥‚ à¥¯à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥§à¥¦à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥¯à¥«.à¥¦à¥¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>à¤°à¥‚ à¥¯à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥§à¥¦à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥¯à¥¬.à¥¬à¥­</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>à¤°à¥‚ à¥®à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥¯à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥®à¥¬.à¥¬à¥­</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34521</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>à¤°à¥‚ à¥ªà¥«.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥«à¥«.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥«à¥¦.à¥¦à¥¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34633</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>à¤°à¥‚ à¥«à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥¬à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥«à¥«.à¥¦à¥¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34747</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>à¤°à¥‚ à¥ªà¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥«à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥ªà¥«.à¥¦à¥¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34860</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>à¤°à¥‚ à¥ªà¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥«à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥ªà¥«.à¥¦à¥¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34974</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>à¤°à¥‚ à¥ªà¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥«à¥¦.à¥¦à¥¦</td>\n",
       "      <td>à¤°à¥‚ à¥ªà¥«.à¥¦à¥¦</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date             commodity    unit    minimum    maximum  \\\n",
       "0      2022-01-01  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.  à¤°à¥‚ à¥§à¥§à¥¦.à¥¦à¥¦  à¤°à¥‚ à¥§à¥¨à¥¦.à¥¦à¥¦   \n",
       "109    2022-01-02  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.  à¤°à¥‚ à¥§à¥§à¥¦.à¥¦à¥¦  à¤°à¥‚ à¥§à¥¨à¥¦.à¥¦à¥¦   \n",
       "216    2022-01-03  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   à¤°à¥‚ à¥¯à¥¦.à¥¦à¥¦  à¤°à¥‚ à¥§à¥¦à¥¦.à¥¦à¥¦   \n",
       "323    2022-01-04  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   à¤°à¥‚ à¥¯à¥¦.à¥¦à¥¦  à¤°à¥‚ à¥§à¥¦à¥¦.à¥¦à¥¦   \n",
       "430    2022-01-05  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   à¤°à¥‚ à¥®à¥¦.à¥¦à¥¦   à¤°à¥‚ à¥¯à¥¦.à¥¦à¥¦   \n",
       "...           ...                   ...     ...        ...        ...   \n",
       "34521  2022-12-27  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   à¤°à¥‚ à¥ªà¥«.à¥¦à¥¦   à¤°à¥‚ à¥«à¥«.à¥¦à¥¦   \n",
       "34633  2022-12-28  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   à¤°à¥‚ à¥«à¥¦.à¥¦à¥¦   à¤°à¥‚ à¥¬à¥¦.à¥¦à¥¦   \n",
       "34747  2022-12-29  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   à¤°à¥‚ à¥ªà¥¦.à¥¦à¥¦   à¤°à¥‚ à¥«à¥¦.à¥¦à¥¦   \n",
       "34860  2022-12-30  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   à¤°à¥‚ à¥ªà¥¦.à¥¦à¥¦   à¤°à¥‚ à¥«à¥¦.à¥¦à¥¦   \n",
       "34974  2022-12-31  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   à¤°à¥‚ à¥ªà¥¦.à¥¦à¥¦   à¤°à¥‚ à¥«à¥¦.à¥¦à¥¦   \n",
       "\n",
       "      average_price  \n",
       "0         à¤°à¥‚ à¥§à¥§à¥«.à¥¦à¥¦  \n",
       "109       à¤°à¥‚ à¥§à¥§à¥«.à¥¦à¥¦  \n",
       "216        à¤°à¥‚ à¥¯à¥«.à¥¦à¥¦  \n",
       "323        à¤°à¥‚ à¥¯à¥¬.à¥¬à¥­  \n",
       "430        à¤°à¥‚ à¥®à¥¬.à¥¬à¥­  \n",
       "...             ...  \n",
       "34521      à¤°à¥‚ à¥«à¥¦.à¥¦à¥¦  \n",
       "34633      à¤°à¥‚ à¥«à¥«.à¥¦à¥¦  \n",
       "34747      à¤°à¥‚ à¥ªà¥«.à¥¦à¥¦  \n",
       "34860      à¤°à¥‚ à¥ªà¥«.à¥¦à¥¦  \n",
       "34974      à¤°à¥‚ à¥ªà¥«.à¥¦à¥¦  \n",
       "\n",
       "[303 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tomato_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43bb759b-7540-425a-9085-b65e3cc99db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mapping Nepali to English digits\n",
    "nep_to_eng = str.maketrans('à¥¦à¥§à¥¨à¥©à¥ªà¥«à¥¬à¥­à¥®à¥¯', '0123456789')\n",
    "\n",
    "# Apply translation to all string columns\n",
    "# df1 = df1.applymap(lambda x: x.translate(nep_to_eng) if isinstance(x, str) else x)\n",
    "df_tomato_big = df_tomato_big.apply(lambda col: col.map(lambda x: x.translate(nep_to_eng) if isinstance(x, str) else x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87b07c2c-1459-4fc6-b80d-63a8ee51dc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>commodity</th>\n",
       "      <th>unit</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>à¤°à¥‚ 110.00</td>\n",
       "      <td>à¤°à¥‚ 120.00</td>\n",
       "      <td>à¤°à¥‚ 115.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>à¤°à¥‚ 110.00</td>\n",
       "      <td>à¤°à¥‚ 120.00</td>\n",
       "      <td>à¤°à¥‚ 115.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>à¤°à¥‚ 90.00</td>\n",
       "      <td>à¤°à¥‚ 100.00</td>\n",
       "      <td>à¤°à¥‚ 95.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>à¤°à¥‚ 90.00</td>\n",
       "      <td>à¤°à¥‚ 100.00</td>\n",
       "      <td>à¤°à¥‚ 96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>à¤°à¥‚ 80.00</td>\n",
       "      <td>à¤°à¥‚ 90.00</td>\n",
       "      <td>à¤°à¥‚ 86.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date             commodity    unit    minimum    maximum  \\\n",
       "0    2022-01-01  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.  à¤°à¥‚ 110.00  à¤°à¥‚ 120.00   \n",
       "109  2022-01-02  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.  à¤°à¥‚ 110.00  à¤°à¥‚ 120.00   \n",
       "216  2022-01-03  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   à¤°à¥‚ 90.00  à¤°à¥‚ 100.00   \n",
       "323  2022-01-04  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   à¤°à¥‚ 90.00  à¤°à¥‚ 100.00   \n",
       "430  2022-01-05  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   à¤°à¥‚ 80.00   à¤°à¥‚ 90.00   \n",
       "\n",
       "    average_price  \n",
       "0       à¤°à¥‚ 115.00  \n",
       "109     à¤°à¥‚ 115.00  \n",
       "216      à¤°à¥‚ 95.00  \n",
       "323      à¤°à¥‚ 96.67  \n",
       "430      à¤°à¥‚ 86.67  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tomato_big.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aad366fe-4a0a-49cc-990b-8d6b9f932847",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tomato_big['minimum']= df_tomato_big['minimum'].str.split(' ').str[1]\n",
    "df_tomato_big['maximum']= df_tomato_big['maximum'].str.split(' ').str[1]\n",
    "df_tomato_big['average_price']= df_tomato_big['average_price'].str.split(' ').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9606c40-30e7-404f-8ec0-d4b7ca03b229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>commodity</th>\n",
       "      <th>unit</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>110.00</td>\n",
       "      <td>120.00</td>\n",
       "      <td>115.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>110.00</td>\n",
       "      <td>120.00</td>\n",
       "      <td>115.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>90.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>95.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>90.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>80.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>86.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34521</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>45.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34633</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>50.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>55.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34747</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>40.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>45.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34860</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>40.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>45.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34974</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)</td>\n",
       "      <td>à¤•à¥‡.à¤œà¥€.</td>\n",
       "      <td>40.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>45.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date             commodity    unit minimum maximum average_price\n",
       "0      2022-01-01  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.  110.00  120.00        115.00\n",
       "109    2022-01-02  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.  110.00  120.00        115.00\n",
       "216    2022-01-03  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   90.00  100.00         95.00\n",
       "323    2022-01-04  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   90.00  100.00         96.67\n",
       "430    2022-01-05  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   80.00   90.00         86.67\n",
       "...           ...                   ...     ...     ...     ...           ...\n",
       "34521  2022-12-27  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   45.00   55.00         50.00\n",
       "34633  2022-12-28  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   50.00   60.00         55.00\n",
       "34747  2022-12-29  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   40.00   50.00         45.00\n",
       "34860  2022-12-30  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   40.00   50.00         45.00\n",
       "34974  2022-12-31  à¤—à¥‹à¤²à¤­à¥‡à¤¡à¤¾ à¤ à¥‚à¤²à¥‹(à¤¨à¥‡à¤ªà¤¾à¤²à¥€)  à¤•à¥‡.à¤œà¥€.   40.00   50.00         45.00\n",
       "\n",
       "[303 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tomato_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89421e26-b8e5-4735-a57f-e1adcd861173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myConda)",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
